{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giacomo/mambaforge/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-04-08 01:52:20.977594: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from utils import f1_score_function\n",
    "from BertClassifier import BertClassifier, init_bert_clf, train_bert_clf, eval_bert_clf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "from torch import nn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.read_csv('subtaskA_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>conspiratorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>âš¡Se non ci fossero soldati non ci sarebbero gu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21/08/21]( [PRE-PRINT]\\n\\nðŸ“„__ \"Shedding of Inf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAURA E DELIRIO ALLA CNN: IL MINISTERO DELLA V...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L'Aspirina non aumenta la sopravvivenza dei pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L'Italia non puo' dare armi lo vieta la Costit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  conspiratorial\n",
       "0  âš¡Se non ci fossero soldati non ci sarebbero gu...               0\n",
       "1  21/08/21]( [PRE-PRINT]\\n\\nðŸ“„__ \"Shedding of Inf...               1\n",
       "2  PAURA E DELIRIO ALLA CNN: IL MINISTERO DELLA V...               1\n",
       "3  L'Aspirina non aumenta la sopravvivenza dei pa...               0\n",
       "4  L'Italia non puo' dare armi lo vieta la Costit...               0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1845 entries, 0 to 1844\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   comment_text    1842 non-null   object\n",
      " 1   conspiratorial  1845 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 29.0+ KB\n"
     ]
    }
   ],
   "source": [
    "texts_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>conspiratorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    comment_text  conspiratorial\n",
       "244          NaN               0\n",
       "263          NaN               0\n",
       "665          NaN               0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df[texts_df['comment_text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = texts_df[texts_df.comment_text.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1842 entries, 0 to 1844\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   comment_text    1842 non-null   object\n",
      " 1   conspiratorial  1842 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 43.2+ KB\n"
     ]
    }
   ],
   "source": [
    "texts_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    925\n",
       "0    917\n",
       "Name: conspiratorial, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df.conspiratorial.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove break line characthers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df.comment_text = texts_df.comment_text.apply(lambda text: text.replace('\\n\\n', ' ').replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80-20 train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing datasets using stratified sampling\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, eval_index in split.split(texts_df, texts_df.conspiratorial):\n",
    "    train_df, val_df = texts_df.iloc[train_index], texts_df.iloc[eval_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1473 entries, 1512 to 1771\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   comment_text    1473 non-null   object\n",
      " 1   conspiratorial  1473 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 34.5+ KB\n",
      "None\n",
      "1    740\n",
      "0    733\n",
      "Name: conspiratorial, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.info())\n",
    "print(train_df.conspiratorial.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 369 entries, 363 to 670\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   comment_text    369 non-null    object\n",
      " 1   conspiratorial  369 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 8.6+ KB\n",
      "None\n",
      "1    185\n",
      "0    184\n",
      "Name: conspiratorial, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(val_df.info())\n",
    "print(val_df.conspiratorial.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-italian-xxl-cased', do_lower_case=False)\n",
    "\n",
    "texts_tr = train_df['comment_text']\n",
    "labels_tr = train_df['conspiratorial'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_tr = train_df['comment_text']\n",
    "labels_tr = train_df['conspiratorial'].to_numpy()\n",
    "\n",
    "texts_val = val_df['comment_text']\n",
    "labels_val = val_df['conspiratorial'].to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe distribution of tokenized texts lengths by trying a simple tokenization on both tr and val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAHpCAYAAABN+X+UAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAu9klEQVR4nO3dfVSVdb7//9eOmw0S7LgZ2OwkwgltFOwGHW+mk3iHWeqUrbH70e9xWjUpSepxRp2ZqFXS17NSZzTt1PKoZS5aZ6VNc2pUyKTh6+GkuJjAOmUrLGwgToZsMNwgXr8/+nXNbIEU3LA/yPOx1rWW1+f67Gu/r0+0Xvu6d1iWZQkAABjpsmAXAAAAukZQAwBgMIIaAACDEdQAABiMoAYAwGAENQAABiOoAQAwGEEtybIseb1ecUs5AMA0BLWkpqYmuVwuNTU1BbsUAAD8ENQAABiMoAYAwGAENQAABiOoAQAwGEENAIDBCGoAAAxGUAMAYDCCGgAAgxHUAAAYjKAGAMBgBDUAAAYjqAEAMBhBDQCAwQhqAAAMRlADAGAwghoAAIMR1AAAGIygBgDAYAQ1AAAGCw12AQPB6dOnVVZW5tc2duxYRUREBKkiAEB/QVD3gbKyMj228XXFpqRLkhpqjmqtpOzs7KDWBQAwH0HdR2JT0pU47MZglwEA6Gc4Rw0AgMEIagAADEZQAwBgMIIaAACDEdQAABiMoAYAwGAENQAABiOoAQAwGEENAIDBCGoAAAxGUAMAYDCCGgAAgxHUAAAYzJigLigokMPhUF5ent1mWZby8/Pl8XgUGRmp7OxsHTlyxO9zPp9Pubm5SkhIUFRUlGbNmqXjx4/3cfUAAPQOI4L64MGDeuGFFzRy5Ei/9tWrV2vNmjXasGGDDh48KLfbralTp6qpqcnuk5eXp127dqmwsFClpaVqbm7WjBkz1N7e3tebAQBAwAU9qJubm3XffffpxRdfVGxsrN1uWZbWrVunlStXavbs2crIyNC2bdv0zTffaMeOHZKkxsZGbd68Wc8++6ymTJmiG264Qdu3b1dlZaWKi4uDtUkAAARM0IN6wYIFuu222zRlyhS/9urqatXV1SknJ8duczqdmjBhgg4cOCBJKi8vV1tbm18fj8ejjIwMu09nfD6fvF6v3wQAgIlCg/nlhYWFOnz4sA4ePNhhWV1dnSQpKSnJrz0pKUmfffaZ3Sc8PNxvT/y7Pt99vjMFBQV64oknLrZ8AAB6XdD2qGtqarRo0SJt375dERERXfZzOBx+85ZldWg71/n6LF++XI2NjfZUU1PTveIBAOgjQQvq8vJy1dfXKysrS6GhoQoNDVVJSYn+8Ic/KDQ01N6TPnfPuL6+3l7mdrvV2tqqhoaGLvt0xul0KiYmxm8CAMBEQQvqyZMnq7KyUhUVFfY0atQo3XfffaqoqNCQIUPkdrtVVFRkf6a1tVUlJSUaP368JCkrK0thYWF+fWpra1VVVWX3AQCgPwvaOero6GhlZGT4tUVFRSk+Pt5uz8vL06pVq5Senq709HStWrVKgwYN0r333itJcrlcmj9/vpYsWaL4+HjFxcVp6dKlyszM7HBxGgAA/VFQLyY7n2XLlqmlpUWPPPKIGhoaNGbMGO3du1fR0dF2n7Vr1yo0NFRz5sxRS0uLJk+erK1btyokJCSIlQMAEBgOy7KsYBcRbF6vVy6XS42Njb1yvnr//v168k9HlDjsRklS/UeH9buZI5SdnR3w7wIAXFqCfh81AADoGkENAIDBCGoAAAxGUAMAYDCCGgAAgxHUAAAYjKAGAMBgBDUAAAYjqAEAMBhBDQCAwQhqAAAMRlADAGAwghoAAIMR1AAAGIygBgDAYAQ1AAAGI6gBADAYQQ0AgMEIagAADEZQAwBgMIIaAACDEdQAABiMoAYAwGAENQAABiOoAQAwGEENAIDBCGoAAAxGUAMAYDCCGgAAgxHUAAAYjKAGAMBgBDUAAAYjqAEAMBhBDQCAwQhqAAAMRlADAGAwghoAAIMR1AAAGIygBgDAYAQ1AAAGC2pQb9q0SSNHjlRMTIxiYmI0btw4/fnPf7aXz5s3Tw6Hw28aO3as3zp8Pp9yc3OVkJCgqKgozZo1S8ePH+/rTQEAoFcENagHDx6sZ555RocOHdKhQ4c0adIk/fSnP9WRI0fsPrfccotqa2vt6a233vJbR15ennbt2qXCwkKVlpaqublZM2bMUHt7e19vDgAAARcazC+fOXOm3/zTTz+tTZs2qaysTCNGjJAkOZ1Oud3uTj/f2NiozZs36+WXX9aUKVMkSdu3b1dKSoqKi4s1bdq0Tj/n8/nk8/nsea/XG4jNAQAg4Iw5R93e3q7CwkKdOnVK48aNs9v379+vxMREDR06VA8++KDq6+vtZeXl5Wpra1NOTo7d5vF4lJGRoQMHDnT5XQUFBXK5XPaUkpLSOxsFAMBFCnpQV1ZW6vLLL5fT6dTDDz+sXbt2afjw4ZKk6dOn65VXXtG+ffv07LPP6uDBg5o0aZK9N1xXV6fw8HDFxsb6rTMpKUl1dXVdfufy5cvV2NhoTzU1Nb23gQAAXISgHvqWpGHDhqmiokInT57Ua6+9prlz56qkpETDhw/XXXfdZffLyMjQqFGjlJqaqjfffFOzZ8/ucp2WZcnhcHS53Ol0yul0BnQ7AADoDUHfow4PD9c111yjUaNGqaCgQNddd51+//vfd9o3OTlZqampOnr0qCTJ7XartbVVDQ0Nfv3q6+uVlJTU67UDANDbgh7U57Isy+9Cr3904sQJ1dTUKDk5WZKUlZWlsLAwFRUV2X1qa2tVVVWl8ePH90m9AAD0pqAe+l6xYoWmT5+ulJQUNTU1qbCwUPv379fu3bvV3Nys/Px83XnnnUpOTtaxY8e0YsUKJSQk6I477pAkuVwuzZ8/X0uWLFF8fLzi4uK0dOlSZWZm2leBAwDQnwU1qL/88ks98MADqq2tlcvl0siRI7V7925NnTpVLS0tqqys1EsvvaSTJ08qOTlZEydO1Kuvvqro6Gh7HWvXrlVoaKjmzJmjlpYWTZ48WVu3blVISEgQtwwAgMAIalBv3ry5y2WRkZHas2fPedcRERGh9evXa/369YEsDQAAIxh3jhoAAPwdQQ0AgMEIagAADEZQAwBgMIIaAACDEdQAABiMoAYAwGAENQAABiOoAQAwGEENAIDBCGoAAAxGUAMAYDCCGgAAgxHUAAAYjKAGAMBgBDUAAAYjqAEAMBhBDQCAwQhqAAAMRlADAGAwghoAAIMR1AAAGIygBgDAYAQ1AAAGI6gBADAYQQ0AgMEIagAADEZQAwBgMIIaAACDEdQAABiMoAYAwGAENQAABiOoAQAwGEENAIDBCGoAAAxGUAMAYDCCGgAAgxHUAAAYjKAGAMBgBDUAAAYLalBv2rRJI0eOVExMjGJiYjRu3Dj9+c9/tpdblqX8/Hx5PB5FRkYqOztbR44c8VuHz+dTbm6uEhISFBUVpVmzZun48eN9vSkAAPSKoAb14MGD9cwzz+jQoUM6dOiQJk2apJ/+9Kd2GK9evVpr1qzRhg0bdPDgQbndbk2dOlVNTU32OvLy8rRr1y4VFhaqtLRUzc3NmjFjhtrb24O1WQAABExQg3rmzJm69dZbNXToUA0dOlRPP/20Lr/8cpWVlcmyLK1bt04rV67U7NmzlZGRoW3btumbb77Rjh07JEmNjY3avHmznn32WU2ZMkU33HCDtm/frsrKShUXF3f5vT6fT16v128CAMBExpyjbm9vV2FhoU6dOqVx48apurpadXV1ysnJsfs4nU5NmDBBBw4ckCSVl5erra3Nr4/H41FGRobdpzMFBQVyuVz2lJKS0nsbBgDARQh6UFdWVuryyy+X0+nUww8/rF27dmn48OGqq6uTJCUlJfn1T0pKspfV1dUpPDxcsbGxXfbpzPLly9XY2GhPNTU1Ad4qAAACIzTYBQwbNkwVFRU6efKkXnvtNc2dO1clJSX2cofD4dffsqwObec6Xx+n0ymn03lxhQMA0AeCvkcdHh6ua665RqNGjVJBQYGuu+46/f73v5fb7ZakDnvG9fX19l622+1Wa2urGhoauuwDAEB/FvSgPpdlWfL5fEpLS5Pb7VZRUZG9rLW1VSUlJRo/frwkKSsrS2FhYX59amtrVVVVZfcBAKA/C+qh7xUrVmj69OlKSUlRU1OTCgsLtX//fu3evVsOh0N5eXlatWqV0tPTlZ6erlWrVmnQoEG69957JUkul0vz58/XkiVLFB8fr7i4OC1dulSZmZmaMmVKMDcNAICACGpQf/nll3rggQdUW1srl8ulkSNHavfu3Zo6daokadmyZWppadEjjzyihoYGjRkzRnv37lV0dLS9jrVr1yo0NFRz5sxRS0uLJk+erK1btyokJCRYmwUAQMA4LMuygl1EsHm9XrlcLjU2NiomJibg69+/f7+e/NMRJQ67UZJU/9Fh/W7mCGVnZwf8uwAAlxbjzlEDAIC/I6gBADAYQQ0AgMEIagAADEZQAwBgMIIaAACDEdQAABiMoAYAwGAENQAABiOoAQAwGEENAIDBCGoAAAxGUAMAYDCCGgAAgxHUAAAYjKAGAMBgBDUAAAYjqAEAMBhBDQCAwQhqAAAMRlADAGAwghoAAIMR1AAAGIygBgDAYAQ1AAAGI6gBADAYQQ0AgMEIagAADEZQAwBgMIIaAACDEdQAABiMoAYAwGAENQAABiOoAQAwGEENAIDBCGoAAAxGUAMAYDCCGgAAgxHUAAAYjKAGAMBgQQ3qgoICjR49WtHR0UpMTNTtt9+ujz76yK/PvHnz5HA4/KaxY8f69fH5fMrNzVVCQoKioqI0a9YsHT9+vC83BQCAXhHUoC4pKdGCBQtUVlamoqIinTlzRjk5OTp16pRfv1tuuUW1tbX29NZbb/ktz8vL065du1RYWKjS0lI1NzdrxowZam9v78vNAQAg4EKD+eW7d+/2m9+yZYsSExNVXl6um2++2W53Op1yu92drqOxsVGbN2/Wyy+/rClTpkiStm/frpSUFBUXF2vatGkdPuPz+eTz+ex5r9cbiM0BACDgjDpH3djYKEmKi4vza9+/f78SExM1dOhQPfjgg6qvr7eXlZeXq62tTTk5OXabx+NRRkaGDhw40On3FBQUyOVy2VNKSkovbA0AABfPmKC2LEuLFy/WTTfdpIyMDLt9+vTpeuWVV7Rv3z49++yzOnjwoCZNmmTvEdfV1Sk8PFyxsbF+60tKSlJdXV2n37V8+XI1NjbaU01NTe9tGAAAFyGoh77/0cKFC/X++++rtLTUr/2uu+6y/52RkaFRo0YpNTVVb775pmbPnt3l+izLksPh6HSZ0+mU0+kMTOEAAPQiI/aoc3Nz9cYbb+idd97R4MGDv7dvcnKyUlNTdfToUUmS2+1Wa2urGhoa/PrV19crKSmp12oGAKAvBDWoLcvSwoULtXPnTu3bt09paWnn/cyJEydUU1Oj5ORkSVJWVpbCwsJUVFRk96mtrVVVVZXGjx/fa7UDANAXgnroe8GCBdqxY4f++Mc/Kjo62j6n7HK5FBkZqebmZuXn5+vOO+9UcnKyjh07phUrVighIUF33HGH3Xf+/PlasmSJ4uPjFRcXp6VLlyozM9O+ChwAgP4qqEG9adMmSVJ2drZf+5YtWzRv3jyFhISosrJSL730kk6ePKnk5GRNnDhRr776qqKjo+3+a9euVWhoqObMmaOWlhZNnjxZW7duVUhISF9uDgAAARfUoLYs63uXR0ZGas+ePeddT0REhNavX6/169cHqjQAAIxgxMVkAACgcwQ1AAAGI6gBADAYQQ0AgMEIagAADEZQAwBgsB4F9ZAhQ3TixIkO7SdPntSQIUMuuigAAPCtHgX1sWPH1N7e3qHd5/Ppiy++uOiiAADAt7r1wJM33njD/veePXvkcrns+fb2dr399tu6+uqrA1YcAAADXbeC+vbbb5ckORwOzZ07129ZWFiYrr76aj377LMBKw4AgIGuW0F99uxZSVJaWpoOHjyohISEXikKAAB8q0fP+q6urg50HQAAoBM9finH22+/rbffflv19fX2nvZ3/v3f//2iCwMAAD0M6ieeeEJPPvmkRo0apeTkZDkcjkDXBQAA1MOgfv7557V161Y98MADga4HAAD8gx7dR93a2qrx48cHuhYAAHCOHgX1L37xC+3YsSPQtQAAgHP06ND36dOn9cILL6i4uFgjR45UWFiY3/I1a9YEpDgAAAa6HgX1+++/r+uvv16SVFVV5beMC8sAAAicHgX1O++8E+g6AABAJ3jNJQAABuvRHvXEiRO/9xD3vn37elwQAAD4ux4F9Xfnp7/T1tamiooKVVVVdXhZBwAA6LkeBfXatWs7bc/Pz1dzc/NFFQQAAP4uoOeo77//fp7zDQBAAAU0qP/rv/5LERERgVwlAAADWo8Ofc+ePdtv3rIs1dbW6tChQ/rtb38bkMIAAEAPg9rlcvnNX3bZZRo2bJiefPJJ5eTkBKQwAADQw6DesmVLoOsAAACd6FFQf6e8vFwffvihHA6Hhg8frhtuuCFQdQEAAPUwqOvr63X33Xdr//79uuKKK2RZlhobGzVx4kQVFhbqBz/4QaDrBABgQOrRVd+5ubnyer06cuSIvv76azU0NKiqqkper1ePPvpooGsEAGDA6tEe9e7du1VcXKwf/ehHdtvw4cP13HPPcTEZAAAB1KM96rNnz3Z4B7UkhYWF6ezZsxddFAAA+FaPgnrSpElatGiR/va3v9ltX3zxhR577DFNnjw5YMUBADDQ9SioN2zYoKamJl199dX64Q9/qGuuuUZpaWlqamrS+vXrA10jAAADVo/OUaekpOjw4cMqKirS//zP/8iyLA0fPlxTpkwJdH0AAAxo3dqj3rdvn4YPHy6v1ytJmjp1qnJzc/Xoo49q9OjRGjFihP7yl7/0SqEAAAxE3QrqdevW6cEHH1RMTEyHZS6XSw899JDWrFkTsOIAABjouhXUf/3rX3XLLbd0uTwnJ0fl5eUXvL6CggKNHj1a0dHRSkxM1O23366PPvrIr49lWcrPz5fH41FkZKSys7N15MgRvz4+n0+5ublKSEhQVFSUZs2apePHj3dn0wAAMFK3gvrLL7/s9Las74SGhup///d/L3h9JSUlWrBggcrKylRUVKQzZ84oJydHp06dsvusXr1aa9as0YYNG3Tw4EG53W5NnTpVTU1Ndp+8vDzt2rVLhYWFKi0tVXNzs2bMmKH29vbubF6faT/TpoqKCu3fv99vOn36dLBLAwAYplsXk1155ZWqrKzUNddc0+ny999/X8nJyRe8vt27d/vNb9myRYmJiSovL9fNN98sy7K0bt06rVy50n615rZt25SUlKQdO3booYceUmNjozZv3qyXX37Zvpht+/btSklJUXFxsaZNm9adTewT3tpqPf/paXlq/v6jp6HmqNZKys7ODlpdAADzdGuP+tZbb9Xvfve7Tvf8Wlpa9Pjjj2vGjBk9LqaxsVGSFBcXJ0mqrq5WXV2d39POnE6nJkyYoAMHDkj69sUgbW1tfn08Ho8yMjLsPufy+Xzyer1+U1+L8QxR4rAb7Sk2Jb3PawAAmK9be9S/+c1vtHPnTg0dOlQLFy7UsGHD5HA49OGHH+q5555Te3u7Vq5c2aNCLMvS4sWLddNNNykjI0OSVFdXJ0lKSkry65uUlKTPPvvM7hMeHq7Y2NgOfb77/LkKCgr0xBNP9KhOAAD6UreCOikpSQcOHNAvf/lLLV++XJZlSZIcDoemTZumjRs3dgjVC7Vw4UK9//77Ki0t7bDM4XD4zVuW1aHtXN/XZ/ny5Vq8eLE97/V6lZKS0oOqAQDoXd1+4ElqaqreeustNTQ06JNPPpFlWUpPT++wR9sdubm5euONN/Tuu+9q8ODBdrvb7Zb07V7zP577rq+vt38QuN1utba2qqGhwa+G+vp6jR8/vtPvczqdcjqdPa4XAIC+0qNHiEpSbGysRo8erR//+Mc9DmnLsrRw4ULt3LlT+/btU1pamt/ytLQ0ud1uFRUV2W2tra0qKSmxQzgrK0thYWF+fWpra1VVVdVlUAMA0F/06BGigbJgwQLt2LFDf/zjHxUdHW2fU3a5XIqMjJTD4VBeXp5WrVql9PR0paena9WqVRo0aJDuvfdeu+/8+fO1ZMkSxcfHKy4uTkuXLlVmZiaPNAUA9HtBDepNmzZJ6nhL0pYtWzRv3jxJ0rJly9TS0qJHHnlEDQ0NGjNmjPbu3avo6Gi7/9q1axUaGqo5c+aopaVFkydP1tatWxUSEtJXmwIAQK8IalB/dzHa93E4HMrPz1d+fn6XfSIiIrR+/Xre3AUAuOT0+Bw1AADofQQ1AAAGI6gBADAYQQ0AgMEIagAADEZQAwBgMIIaAACDEdQAABiMoAYAwGAENQAABiOoAQAwGEENAIDBCGoAAAxGUAMAYDCCGgAAgxHUAAAYjKAGAMBgBDUAAAYjqAEAMBhBDQCAwQhqAAAMRlADAGCw0GAXcKk5ffq0ysrK/NoqKip01goJUkUAgP6MoA6wsrIyPbbxdcWmpNttn5eXKm7Y6CBWBQDorwjqXhCbkq7EYTfa8w01HwexGgBAf8Y5agAADEZQAwBgMIIaAACDEdQAABiMoAYAwGAENQAABiOoAQAwGEENAIDBCGoAAAxGUAMAYDCCGgAAgxHUAAAYjKAGAMBgBDUAAAbjNZcGO336tMrKyjq0jx07VhEREUGoCADQ14K6R/3uu+9q5syZ8ng8cjgcev311/2Wz5s3Tw6Hw28aO3asXx+fz6fc3FwlJCQoKipKs2bN0vHjx/twK3pPWVmZHtv4up780xF7emzj652GNwDg0hTUoD516pSuu+46bdiwocs+t9xyi2pra+3prbfe8luel5enXbt2qbCwUKWlpWpubtaMGTPU3t7e2+X3idiUdCUOu9GeYlPSg10SAKAPBfXQ9/Tp0zV9+vTv7eN0OuV2uztd1tjYqM2bN+vll1/WlClTJEnbt29XSkqKiouLNW3atIDXDABAXzL+HPX+/fuVmJioK664QhMmTNDTTz+txMRESVJ5ebna2tqUk5Nj9/d4PMrIyNCBAwe6DGqfzyefz2fPe73e3t2IC9B+pk0VFRV+bRUVFTprhQSnIACAEYwO6unTp+tnP/uZUlNTVV1drd/+9reaNGmSysvL5XQ6VVdXp/DwcMXGxvp9LikpSXV1dV2ut6CgQE888URvl98t3tpqPf/paXlqwuy2z8tLFTdsdBCrAgAEm9FBfdddd9n/zsjI0KhRo5Samqo333xTs2fP7vJzlmXJ4XB0uXz58uVavHixPe/1epWSkhKYoi9CjGeIEofdaM831HwcxGoAACboV/dRJycnKzU1VUePHpUkud1utba2qqGhwa9ffX29kpKSulyP0+lUTEyM3wQAgIn6VVCfOHFCNTU1Sk5OliRlZWUpLCxMRUVFdp/a2lpVVVVp/PjxwSoTAICACeqh7+bmZn3yySf2fHV1tSoqKhQXF6e4uDjl5+frzjvvVHJyso4dO6YVK1YoISFBd9xxhyTJ5XJp/vz5WrJkieLj4xUXF6elS5cqMzPTvgocAID+LKhBfejQIU2cONGe/+688dy5c7Vp0yZVVlbqpZde0smTJ5WcnKyJEyfq1VdfVXR0tP2ZtWvXKjQ0VHPmzFFLS4smT56srVu3KiSEq6UBAP1fUIM6OztblmV1uXzPnj3nXUdERITWr1+v9evXB7I0AACM0K/OUQMAMNAQ1AAAGIygBgDAYAQ1AAAGI6gBADAYQQ0AgMEIagAADEZQAwBgMIIaAACDEdQAABiMoAYAwGAENQAABiOoAQAwGEENAIDBCGoAAAxGUAMAYDCCGgAAgxHUAAAYjKAGAMBgBDUAAAYjqAEAMBhBDQCAwUKDXQC6p/1MmyoqKjq0jx07VhEREX1fEACgVxHU/Yy3tlrPf3panpowu62h5qjWSsrOzg5aXQCA3kFQ90MxniFKHHZjsMsAAPQBzlEDAGAwghoAAIMR1AAAGIygBgDAYAQ1AAAGI6gBADAYQQ0AgMEIagAADEZQAwBgMIIaAACDEdQAABiMoAYAwGAENQAABiOoAQAwGEENAIDBghrU7777rmbOnCmPxyOHw6HXX3/db7llWcrPz5fH41FkZKSys7N15MgRvz4+n0+5ublKSEhQVFSUZs2apePHj/fhVgAA0HuCGtSnTp3Sddddpw0bNnS6fPXq1VqzZo02bNiggwcPyu12a+rUqWpqarL75OXladeuXSosLFRpaamam5s1Y8YMtbe399VmAADQa0KD+eXTp0/X9OnTO11mWZbWrVunlStXavbs2ZKkbdu2KSkpSTt27NBDDz2kxsZGbd68WS+//LKmTJkiSdq+fbtSUlJUXFysadOm9dm2AADQG4w9R11dXa26ujrl5OTYbU6nUxMmTNCBAwckSeXl5Wpra/Pr4/F4lJGRYffpjM/nk9fr9ZsAADCRsUFdV1cnSUpKSvJrT0pKspfV1dUpPDxcsbGxXfbpTEFBgVwulz2lpKQEuHoAAALD2KD+jsPh8Ju3LKtD27nO12f58uVqbGy0p5qamoDUCgBAoBkb1G63W5I67BnX19fbe9lut1utra1qaGjosk9nnE6nYmJi/CYAAExkbFCnpaXJ7XarqKjIbmttbVVJSYnGjx8vScrKylJYWJhfn9raWlVVVdl9AADoz4J61Xdzc7M++eQTe766uloVFRWKi4vTVVddpby8PK1atUrp6elKT0/XqlWrNGjQIN17772SJJfLpfnz52vJkiWKj49XXFycli5dqszMTPsqcAAA+rOgBvWhQ4c0ceJEe37x4sWSpLlz52rr1q1atmyZWlpa9Mgjj6ihoUFjxozR3r17FR0dbX9m7dq1Cg0N1Zw5c9TS0qLJkydr69atCgkJ6fPtAQAg0IIa1NnZ2bIsq8vlDodD+fn5ys/P77JPRESE1q9fr/Xr1/dChf1D+5k2VVRUdGgfO3asIiIi+r4gAEDABDWoERje2mo9/+lpeWrC7LaGmqNaq29/DAEA+i+C+hIR4xmixGE3BrsMAECAGXvVNwAAIKgBADAaQQ0AgMEIagAADMbFZJeozm7Z4nYtAOh/COpL1Lm3bHG7FgD0TwT1JYxbtgCg/+McNQAABiOoAQAwGEENAIDBCGoAAAxGUAMAYDCCGgAAgxHUAAAYjKAGAMBgBDUAAAYjqAEAMBhBDQCAwQhqAAAMRlADAGAwghoAAIMR1AAAGIygBgDAYAQ1AAAGI6gBADAYQQ0AgMEIagAADBYa7ALQN9rPtKmioqJD+9ixYxUREdH3BQEALghBPUB4a6v1/Ken5akJs9saao5qraTs7Oyg1QUA+H4E9QAS4xmixGE3BrsMAEA3cI4aAACDEdQAABiMoAYAwGAENQAABiOoAQAwGEENAIDBCGoAAAxGUAMAYDCjgzo/P18Oh8Nvcrvd9nLLspSfny+Px6PIyEhlZ2fryJEjQay4f/nusaL79+/3m06fPh3s0gAA/z/jn0w2YsQIFRcX2/MhISH2v1evXq01a9Zo69atGjp0qJ566ilNnTpVH330kaKjo4NRbr/CY0UBwHzGB3VoaKjfXvR3LMvSunXrtHLlSs2ePVuStG3bNiUlJWnHjh166KGHulynz+eTz+ez571eb+AL7yd4rCgAmM3oQ9+SdPToUXk8HqWlpenuu+/Wp59+Kkmqrq5WXV2dcnJy7L5Op1MTJkzQgQMHvnedBQUFcrlc9pSSktKr2wAAQE8ZHdRjxozRSy+9pD179ujFF19UXV2dxo8frxMnTqiurk6SlJSU5PeZpKQke1lXli9frsbGRnuqqanptW0AAOBiGH3oe/r06fa/MzMzNW7cOP3whz/Utm3bNHbsWEmSw+Hw+4xlWR3azuV0OuV0OgNfMAAAAWb0HvW5oqKilJmZqaNHj9rnrc/de66vr++wlw0AQH/Vr4La5/Ppww8/VHJystLS0uR2u1VUVGQvb21tVUlJicaPHx/EKgEACByjD30vXbpUM2fO1FVXXaX6+no99dRT8nq9mjt3rhwOh/Ly8rRq1Sqlp6crPT1dq1at0qBBg3TvvfcGu3QAAALC6KA+fvy47rnnHn311Vf6wQ9+oLFjx6qsrEypqamSpGXLlqmlpUWPPPKIGhoaNGbMGO3du5d7qAEAlwyjg7qwsPB7lzscDuXn5ys/P79vCgIAoI/1q3PUAAAMNAQ1AAAGI6gBADAYQQ0AgMEIagAADEZQAwBgMIIaAACDEdQAABiMoAYAwGAENQAABjP6EaLoe+1n2lRRUdGhfezYsYqIiOj7ggBggCOo4cdbW63nPz0tT02Y3dZQc1RrJWVnZwetLgAYqAhqdBDjGaLEYTfa8+xlA0DwENQ4L/ayASB4CGpckHP3sgEAfYOrvgEAMBh71Og1p0+fVllZWYd2zm0DwIUjqNEjnV1gdm4Al5WV6bGNrys2Jd1u49w2AHQPQY0eOfcCs64CODYlnXPbAHARCGr0GBeYAUDv42IyAAAMxh41+hQPTwGA7iGo0ad4eAoAdA9BjYDobE+5oqJCZ62QDn15RCkAXDiCGgHR2Z7y5+Wlihs2ukefZS8bAL5FUCNgzt1Tbqj5uMefBQB8i6u+AQAwGHvU6Dc6eyQp57EBXOoIavQb5z6S9ELPY/PMcQD9GUENI3V1Fblr8A/tc9md9WltbZUkhYeH+31u6/+rVtxVQ+02LlYD0F8Q1DDShVxF3nmfdxQaHS/P0JEdPheIi9XYOwfQ1whqGOtCriLvrE9YrKfHV5+fz4W+EYxABxAoBDUGpAs9bC51DNcLeSMYr/gEECgENQakCz1sfjHhyis+AQQCQY0B60IOmwNAsPHAEwAADMYeNfA9zj2X3dmLRrrzQhIA6C6CGvge557L7uxFIxfzQhIAOB+CGjiPfzyX3dWtXhfzQpKBoKePf+U2N4CgBvrMQH7vdk8f/8p968AlFNQbN27Uv/7rv6q2tlYjRozQunXr9E//9E/BLguwdXaI/MSxD/V/Kip0/fXX+/UNVMB0FmCd3S/eF4HW09vVuG+9f+LHU+BcEkH96quvKi8vTxs3btRPfvIT/du//ZumT5+uDz74QFdddVWwywNsnR0if/7tD88b3j09TNzZc87PvV/8Yn4sXOgPgXMvrruYowsX8hz4zvpd6ANtOhOM0DHlR1ZPT1sE8mhIX4z/ud9xMX8vgXZJBPWaNWs0f/58/eIXv5AkrVu3Tnv27NGmTZtUUFDQob/P55PP57PnGxsbJUler/eiazl16pS++rRKZ3wtf1//344pxOvV38JCOp3vi7b+vv5L+jsvj/P7e2n6skb/d9sRXbG7XJL0zddf6pezJykzM1Pfp7KyUpt27tOguCS77cSxD+W6OlMx/7D+s2fa1N7Wan/nud8XiO8MiYzWFUmDO9RxtvXb/++OV/xF//dd73m/s7KyUl99+pnf+HT22XPX31m/zuq6mO280M/21IWMbW/X0Fkd3Rmz9jaf33+79jafysrKdOrUqS7X39l39MX4n/sdXf29bHx8UUCP1kZHR8vhcHx/J6uf8/l8VkhIiLVz506/9kcffdS6+eabO/3M448/bkliYmJiYmIK6tTY2HjenOv3e9RfffWV2tvblZSU5NeelJSkurq6Tj+zfPlyLV682J4/e/asvv76a8XHx5//l00XvF6vUlJSVFNTo5iYmB6tA51jbHsPY9s7GNfec6mNbXR09Hn79Pug/s65AWtZVpeh63Q65XQ6/dquuOKKgNQRExNzSfzxmIix7T2Mbe9gXHvPQBrbfv8I0YSEBIWEhHTYe66vr++wlw0AQH/T74M6PDxcWVlZKioq8msvKirS+PHjg1QVAACBcUkc+l68eLEeeOABjRo1SuPGjdMLL7ygzz//XA8//HCf1eB0OvX44493OKSOi8fY9h7Gtncwrr1nII6tw7IsK9hFBMLGjRu1evVq1dbWKiMjQ2vXrtXNN98c7LIAALgol0xQAwBwKer356gBALiUEdQAABiMoAYAwGAENQAABiOoA2Tjxo1KS0tTRESEsrKy9Je//CXYJRmtoKBAo0ePVnR0tBITE3X77bfro48+8utjWZby8/Pl8XgUGRmp7OxsHTlyxK+Pz+dTbm6uEhISFBUVpVmzZun48eN9uSlGKygokMPhUF5ent3GuPbcF198ofvvv1/x8fEaNGiQrr/+epWX//3lIIxt9505c0a/+c1vlJaWpsjISA0ZMkRPPvmkzp49a/cZ8ON6MS/EwLcKCwutsLAw68UXX7Q++OADa9GiRVZUVJT12WefBbs0Y02bNs3asmWLVVVVZVVUVFi33XabddVVV1nNzc12n2eeecaKjo62XnvtNauystK66667rOTkZMvr9dp9Hn74YevKK6+0ioqKrMOHD1sTJ060rrvuOuvMmTPB2CyjvPfee9bVV19tjRw50lq0aJHdzrj2zNdff22lpqZa8+bNs/77v//bqq6utoqLi61PPvnE7sPYdt9TTz1lxcfHW//5n/9pVVdXW//xH/9hXX755da6devsPgN9XAnqAPjxj39sPfzww35t1157rfXrX/86SBX1P/X19ZYkq6SkxLIsyzp79qzldrutZ555xu5z+vRpy+VyWc8//7xlWZZ18uRJKywszCosLLT7fPHFF9Zll11m7d69u283wDBNTU1Wenq6VVRUZE2YMMEOasa15371q19ZN910U5fLGdueue2226x//ud/9mubPXu2df/991uWxbhalmVx6Psitba2qry8XDk5OX7tOTk5OnDgQJCq6n++eyd4XFycJKm6ulp1dXV+4+p0OjVhwgR7XMvLy9XW1ubXx+PxKCMjY8CP/YIFC3TbbbdpypQpfu2Ma8+98cYbGjVqlH72s58pMTFRN9xwg1588UV7OWPbMzfddJPefvttffzxx5Kkv/71ryotLdWtt94qiXGVLpFHiAZTT16zCX+WZWnx4sW66aablJGRIUn22HU2rp999pndJzw8XLGxsR36DOSxLyws1OHDh3Xw4MEOyxjXnvv000+1adMmLV68WCtWrNB7772nRx99VE6nUz//+c8Z2x761a9+pcbGRl177bUKCQlRe3u7nn76ad1zzz2S+JuVCOqA6c5rNuFv4cKFev/991VaWtphWU/GdSCPfU1NjRYtWqS9e/cqIiKiy36Ma/edPXtWo0aN0qpVqyRJN9xwg44cOaJNmzbp5z//ud2Pse2eV199Vdu3b9eOHTs0YsQIVVRUKC8vTx6PR3PnzrX7DeRx5dD3ReI1mxcnNzdXb7zxht555x0NHjzYbne73ZL0vePqdrvV2tqqhoaGLvsMNOXl5aqvr1dWVpZCQ0MVGhqqkpIS/eEPf1BoaKg9Loxr9yUnJ2v48OF+bT/60Y/0+eefS+Jvtqf+5V/+Rb/+9a919913KzMzUw888IAee+wxFRQUSGJcJYL6ovGazZ6xLEsLFy7Uzp07tW/fPqWlpfktT0tLk9vt9hvX1tZWlZSU2OOalZWlsLAwvz61tbWqqqoasGM/efJkVVZWqqKiwp5GjRql++67TxUVFRoyZAjj2kM/+clPOtxC+PHHHys1NVUSf7M99c033+iyy/yjKCQkxL49i3EVt2cFwne3Z23evNn64IMPrLy8PCsqKso6duxYsEsz1i9/+UvL5XJZ+/fvt2pra+3pm2++sfs888wzlsvlsnbu3GlVVlZa99xzT6e3ZAwePNgqLi62Dh8+bE2aNOmSuSUjUP7xqm/LYlx76r333rNCQ0Otp59+2jp69Kj1yiuvWIMGDbK2b99u92Fsu2/u3LnWlVdead+etXPnTishIcFatmyZ3WegjytBHSDPPfeclZqaaoWHh1s33nijfZsROiep02nLli12n7Nnz1qPP/645Xa7LafTad18881WZWWl33paWlqshQsXWnFxcVZkZKQ1Y8YM6/PPP+/jrTHbuUHNuPbcn/70JysjI8NyOp3Wtddea73wwgt+yxnb7vN6vdaiRYusq666yoqIiLCGDBlirVy50vL5fHafgT6uvOYSAACDcY4aAACDEdQAABiMoAYAwGAENQAABiOoAQAwGEENAIDBCGoAAAxGUAMAYDCCGgAAgxHUAAAYjKAGAMBg/x+oejgn8FEtLQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_len_list = []\n",
    "\n",
    "for sentence in texts_tr:\n",
    "    input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    tokenized_len_list.append(len(input_ids))\n",
    "for sentence in texts_val:\n",
    "    input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    tokenized_len_list.append(len(input_ids))\n",
    "\n",
    "sns.displot(tokenized_len_list)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum tokenized length is above the BERT max_lenght limit of 512. Very few texts are above this limit, so we truncate to 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/giacomo/mambaforge/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "# Tr set\n",
    "input_ids_tr = []\n",
    "attention_masks_tr = []\n",
    "\n",
    "# `encode_plus` will:\n",
    "#   1. Tokenize the sentence, 2. Prepend the `[CLS]` token to the start, 3. Append the `[SEP]` token to the end\n",
    "#   4. Map tokens to their IDs, 5. Pad or truncate the sentence to `max_length`, 6. Create attention masks for [PAD] tokens\n",
    "\n",
    "for sentence in texts_tr:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 512,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence and attention mask to the list.    \n",
    "    input_ids_tr.append(encoded_dict['input_ids'])\n",
    "    attention_masks_tr.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Val set\n",
    "input_ids_val = []\n",
    "attention_masks_val = []\n",
    "\n",
    "for sentence in texts_val:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 512,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence and attention mask to the list.    \n",
    "    input_ids_val.append(encoded_dict['input_ids'])\n",
    "    attention_masks_val.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists into tensors\n",
    "\n",
    "input_ids_tr = torch.cat(input_ids_tr, dim=0)\n",
    "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
    "\n",
    "attention_masks_tr = torch.cat(attention_masks_tr, dim=0)\n",
    "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
    "\n",
    "labels_tr = torch.tensor(labels_tr)\n",
    "labels_val = torch.tensor(labels_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap data into a TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = TensorDataset(input_ids_tr, attention_masks_tr, labels_tr)\n",
    "val_dataset = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataLoader needs to know our batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the DataLoaders for our training and validation sets. Tr samples are taken in random order, while validation are taken sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataloader = DataLoader(tr_dataset, sampler=RandomSampler(tr_dataset), batch_size = batch_size)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size = batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giacomo/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541990/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'allocated_bytes.all.current'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49mcuda\u001b[39m.\u001b[39;49mmemory_summary())\n",
      "File \u001b[0;32m~/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/cuda/memory.py:496\u001b[0m, in \u001b[0;36mmemory_summary\u001b[0;34m(device, abbreviated)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[39mfor\u001b[39;00m submetric_key, submetric_name \u001b[39min\u001b[39;00m submetrics:\n\u001b[1;32m    494\u001b[0m     prefix \u001b[39m=\u001b[39m metric_key \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m submetric_key \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 496\u001b[0m     current \u001b[39m=\u001b[39m stats[prefix \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mcurrent\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m    497\u001b[0m     peak \u001b[39m=\u001b[39m stats[prefix \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpeak\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    498\u001b[0m     allocated \u001b[39m=\u001b[39m stats[prefix \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallocated\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'allocated_bytes.all.current'"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set save folder for this run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-08 01:51:08.420811\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "curr_date = datetime.now()\n",
    "\n",
    "print(datetime.now())\n",
    "\n",
    "save_folder_pth = './bert_subtaskA/{}_{}_{}-{}.{}'.format(curr_date.day, curr_date.month, curr_date.day, curr_date.hour, curr_date.minute)\n",
    "if(not os.path.exists(save_folder_pth)):\n",
    "    os.makedirs(save_folder_pth)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixed general hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 15\n",
    "\n",
    "\n",
    "# Num batches*num epochs\n",
    "tr_steps = len(tr_dataloader)*max_epochs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable grid searched hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_list = [0.5e-5, 0.2e-5, 0.8e-5]\n",
    "warmup_perc_list = [0.1, 0.05] # Percentage of warmup steps for scheduler on the total tr steps\n",
    "clf_head_list = []\n",
    "\n",
    "head1 = nn.Sequential(\n",
    "                nn.Linear(768, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.25),\n",
    "                nn.Linear(128, 2),\n",
    "                )\n",
    "clf_head_list.append((head1, '2_layers_S')) # Each head obeject is composed by a tuple (head, name)\n",
    "\n",
    "head2 = nn.Sequential(\n",
    "                nn.Linear(768, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.25),\n",
    "                nn.Linear(256, 2),\n",
    "                )\n",
    "clf_head_list.append((head2, '2_layers_M'))\n",
    "\n",
    "head3 = nn.Sequential(\n",
    "                nn.Linear(768, 512),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(512, 32),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.2),\n",
    "                nn.Linear(32, 2),\n",
    "                )\n",
    "clf_head_list.append((head3, '3_layers_M'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize, train/eval and save function for each grid search run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval_model(lr, warmup_steps, head, model_folder_pth):\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    #print(torch.cuda.memory_summary())\n",
    "\n",
    "    # Initialize model\n",
    "    bert_clf_model, loss_function, optimizer, scheduler, device = init_bert_clf(tr_steps=tr_steps, lr_rate=lr, scheduler_warmp_steps=warmup_steps, head=head)\n",
    "\n",
    "    for epoch_i in range(max_epochs):\n",
    "        print('Epoch: {}'.format(epoch_i))\n",
    "\n",
    "        # Train\n",
    "        avg_epoch_loss_tr, acc_score_tr, f1_score_tr, bert_clf_model, optimizer, scheduler = train_bert_clf(bert_clf_model, tr_dataloader, loss_function, optimizer, scheduler, device)\n",
    "\n",
    "\n",
    "        print('TRAINING | Tr Loss: {} - Tr acc: {} - Tr f1: {}'.format(avg_epoch_loss_tr, acc_score_tr, f1_score_tr))\n",
    "\n",
    "        # Eval\n",
    "        avg_epoch_loss_val, acc_score_val, f1_score_val, predictions, labels = eval_bert_clf(bert_clf_model, val_dataloader, loss_function, device)\n",
    "        print('EVALUATION | Val Loss: {} - Val acc: {} - Val f1: {}'.format(avg_epoch_loss_val, acc_score_val, f1_score_val))\n",
    "\n",
    "        # Save\n",
    "        model_save_pth = os.path.join(model_folder_pth, 'bert_clf.pt')\n",
    "        torch.save({\n",
    "                    'epoch': epoch_i,\n",
    "                    'model_state_dict': bert_clf_model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'schdeduler_state_dict': scheduler.state_dict(),\n",
    "                    'tr_loss': avg_epoch_loss_tr,\n",
    "                    'val_loss': avg_epoch_loss_val,\n",
    "                    'tr_acc': acc_score_tr,\n",
    "                    'val_acc': acc_score_val,\n",
    "                    'tr_f1': f1_score_tr,\n",
    "                    'val_f1': f1_score_val,\n",
    "                    'val_preds': predictions\n",
    "                    }, model_save_pth)\n",
    "\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing 18 trials in grid search\n",
      "Executing model with lr=5e-06, warmup perc.=0.1, head=2_layers_S\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-italian-xxl-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/giacomo/mambaforge/envs/nlp/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/home/giacomo/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/cuda/__init__.py:88: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541990/work/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n",
      "Epoch: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m model_folder_pth \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_folder_pth, model_folder_str)\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mExecuting model with lr=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, warmup perc.=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, head=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(lr, warmup_perc, clf_head_tuple[\u001b[39m1\u001b[39m]))\n\u001b[0;32m---> 15\u001b[0m train_eval_model(lr, warmup_steps\u001b[39m=\u001b[39;49mwarmup_perc\u001b[39m*\u001b[39;49mtr_steps, head\u001b[39m=\u001b[39;49mclf_head_tuple[\u001b[39m0\u001b[39;49m], model_folder_pth\u001b[39m=\u001b[39;49mmodel_folder_pth)\n",
      "Cell \u001b[0;32mIn[27], line 13\u001b[0m, in \u001b[0;36mtrain_eval_model\u001b[0;34m(lr, warmup_steps, head, model_folder_pth)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch_i))\n\u001b[1;32m     12\u001b[0m \u001b[39m# Train\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m avg_epoch_loss_tr, acc_score_tr, f1_score_tr, bert_clf_model, optimizer, scheduler \u001b[39m=\u001b[39m train_bert_clf(bert_clf_model, tr_dataloader, loss_function, optimizer, scheduler, device)\n\u001b[1;32m     16\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTRAINING | Tr Loss: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m - Tr acc: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m - Tr f1: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(avg_epoch_loss_tr, acc_score_tr, f1_score_tr))\n\u001b[1;32m     18\u001b[0m \u001b[39m# Eval\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/git_devel/nlp-EVALITA2023-ACTI-challenge/BertClassifier.py:110\u001b[0m, in \u001b[0;36mtrain_bert_clf\u001b[0;34m(model, tr_dataloader, loss_function, optimizer, scheduler, device)\u001b[0m\n\u001b[1;32m    107\u001b[0m _, b_preds \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(raw_preds, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    109\u001b[0m \u001b[39m# Perform a backward pass to calculate gradients\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    112\u001b[0m \u001b[39m# Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39m1.0\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_trials = len(lr_list) * len(warmup_perc_list) * len(clf_head_list)\n",
    "print('Executing {} trials in grid search'.format(num_trials))\n",
    "\n",
    "\n",
    "for lr in lr_list:\n",
    "    for clf_head_tuple in clf_head_list:\n",
    "        for warmup_perc in warmup_perc_list:\n",
    "            \n",
    "            # Model save path subfolder\n",
    "            model_folder_str = 'lr{}_warmup{}_head_{}'.format(lr, warmup_perc, clf_head_tuple[1])\n",
    "            model_folder_pth = os.path.join(save_folder_pth, model_folder_str)\n",
    "\n",
    "            print('Executing model with lr={}, warmup perc.={}, head={}'.format(lr, warmup_perc, clf_head_tuple[1]))\n",
    "\n",
    "            train_eval_model(lr, warmup_steps=warmup_perc*tr_steps, head=clf_head_tuple[0], model_folder_pth=model_folder_pth)\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rate = 0.5e-5\n",
    "scheduler_warmup_step = 0\n",
    "max_epochs = 12\n",
    "\n",
    "# Num batches*num epochs\n",
    "tr_steps = len(tr_dataloader)*max_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0 were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/giacomo/mambaforge/envs/nlp/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3080 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "bert_clf_model, loss_function, optimizer, scheduler, device = init_bert_clf(tr_steps=tr_steps, lr_rate=lr_rate, scheduler_warmp_steps=scheduler_warmup_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using as device: cuda\n"
     ]
    }
   ],
   "source": [
    "print('Using as device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-07 20:54:26.856705\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "curr_date = datetime.now()\n",
    "\n",
    "print(datetime.now())\n",
    "\n",
    "save_folder_pth = './bert_subtaskA/{}_{}_{}-{}.{}'.format(curr_date.day, curr_date.month, curr_date.day, curr_date.hour, curr_date.minute)\n",
    "if(not os.path.exists(save_folder_pth)):\n",
    "    os.makedirs(save_folder_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_optimizer = optimizer\n",
    "curr_scheduler = scheduler\n",
    "curr_bert_clf = bert_clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0| Tr Loss: 0.5996617819032362 - Tr acc: 0.6822810590631364 - Tr f1: 0.6821402750317231\n",
      "EVALUATION | Val Loss: 0.5791960420707861 - Val acc: 0.7073170731707317 - Val f1: 0.706175533797334\n",
      "Epoch: 1| Tr Loss: 0.5012985153864788 - Tr acc: 0.7522063815342838 - Tr f1: 0.7515096053188024\n",
      "EVALUATION | Val Loss: 0.5726963058114052 - Val acc: 0.7100271002710027 - Val f1: 0.7099930221455066\n",
      "Epoch: 2| Tr Loss: 0.38508068097214543 - Tr acc: 0.8268839103869654 - Tr f1: 0.8267149163619152\n",
      "EVALUATION | Val Loss: 0.676938553651174 - Val acc: 0.7046070460704607 - Val f1: 0.7046070460704607\n",
      "Epoch: 3| Tr Loss: 0.2432950676609111 - Tr acc: 0.9056347589952478 - Tr f1: 0.9055504838330966\n",
      "EVALUATION | Val Loss: 0.7926696756233772 - Val acc: 0.6802168021680217 - Val f1: 0.6793667157584684\n",
      "Epoch: 4| Tr Loss: 0.15581155434170718 - Tr acc: 0.9484046164290564 - Tr f1: 0.9483941274740836\n",
      "EVALUATION | Val Loss: 1.0593588165938854 - Val acc: 0.6937669376693767 - Val f1: 0.6937579412002322\n",
      "Epoch: 5| Tr Loss: 0.11562833795073613 - Tr acc: 0.9674134419551935 - Tr f1: 0.9674068173520529\n",
      "EVALUATION | Val Loss: 1.3565829715225846 - Val acc: 0.6937669376693767 - Val f1: 0.6917293233082707\n",
      "Epoch: 6| Tr Loss: 0.08582086607773778 - Tr acc: 0.9775967413441955 - Tr f1: 0.977593395424091\n",
      "EVALUATION | Val Loss: 1.3942438733453553 - Val acc: 0.7154471544715447 - Val f1: 0.7153719008264463\n",
      "Epoch: 7| Tr Loss: 0.05299507729866872 - Tr acc: 0.9877800407331976 - Tr f1: 0.9877790888475083\n",
      "EVALUATION | Val Loss: 1.4747529256468017 - Val acc: 0.7100271002710027 - Val f1: 0.7100185814904852\n",
      "Epoch: 8| Tr Loss: 0.04890345529808352 - Tr acc: 0.988458927359131 - Tr f1: 0.9884583954215214\n",
      "EVALUATION | Val Loss: 1.561421951899926 - Val acc: 0.7046070460704607 - Val f1: 0.7044681366966208\n",
      "Epoch: 9| Tr Loss: 0.042758311032347625 - Tr acc: 0.9925322471147319 - Tr f1: 0.9925315724628296\n",
      "EVALUATION | Val Loss: 1.5562932845205069 - Val acc: 0.7181571815718157 - Val f1: 0.7181551116333724\n",
      "Epoch: 10| Tr Loss: 0.032826891271597755 - Tr acc: 0.9925322471147319 - Tr f1: 0.992531902919808\n",
      "EVALUATION | Val Loss: 1.5635137061278026 - Val acc: 0.7127371273712737 - Val f1: 0.7127181385510313\n",
      "Epoch: 11| Tr Loss: 0.04391695895753 - Tr acc: 0.9918533604887984 - Tr f1: 0.991852725898339\n",
      "EVALUATION | Val Loss: 1.5653583568831284 - Val acc: 0.7073170731707317 - Val f1: 0.7073149236192715\n"
     ]
    }
   ],
   "source": [
    "for epoch_i in range(max_epochs):\n",
    "    # Train\n",
    "    avg_epoch_loss_tr, acc_score_tr, f1_score_tr, model, optimizer, scheduler = train_bert_clf(bert_clf_model, tr_dataloader, loss_function, optimizer, scheduler, device)\n",
    "    curr_optimizer = optimizer\n",
    "    curr_scheduler = scheduler\n",
    "    curr_bert_clf = model\n",
    "    \n",
    "    print('Epoch: {}| Tr Loss: {} - Tr acc: {} - Tr f1: {}'.format(epoch_i, avg_epoch_loss_tr, acc_score_tr, f1_score_tr))\n",
    "\n",
    "    # Eval\n",
    "    avg_epoch_loss_val, acc_score_val, f1_score_val, predictions, labels = eval_bert_clf(bert_clf_model, val_dataloader, loss_function, device)\n",
    "    print('EVALUATION | Val Loss: {} - Val acc: {} - Val f1: {}'.format(avg_epoch_loss_val, acc_score_val, f1_score_val))\n",
    "\n",
    "    # Save\n",
    "    save_path = os.path.join(save_folder_pth, 'bert_clf.pt')\n",
    "    torch.save({\n",
    "                'epoch': epoch_i,\n",
    "                'model_state_dict': curr_bert_clf.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'schdeduler_state_dict': scheduler.state_dict(),\n",
    "                'tr_loss': avg_epoch_loss_tr,\n",
    "                'val_loss': avg_epoch_loss_val,\n",
    "                'tr_acc': acc_score_tr,\n",
    "                'val_acc': acc_score_val,\n",
    "                'tr_f1': f1_score_tr,\n",
    "                'val_f1': f1_score_val,\n",
    "                'val_preds': predictions\n",
    "                }, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
