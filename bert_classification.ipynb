{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giacomo/mambaforge/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-03-20 16:18:21.467281: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "from os import path\n",
    "\n",
    "from utils import f1_score_function\n",
    "from BertClassifier import BertClassifier, init_bert_clf, train_bert_clf, eval_bert_clf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.read_csv('subtaskA_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>conspiratorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>âš¡Se non ci fossero soldati non ci sarebbero gu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21/08/21]( [PRE-PRINT]\\n\\nðŸ“„__ \"Shedding of Inf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAURA E DELIRIO ALLA CNN: IL MINISTERO DELLA V...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L'Aspirina non aumenta la sopravvivenza dei pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L'Italia non puo' dare armi lo vieta la Costit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  conspiratorial\n",
       "0  âš¡Se non ci fossero soldati non ci sarebbero gu...               0\n",
       "1  21/08/21]( [PRE-PRINT]\\n\\nðŸ“„__ \"Shedding of Inf...               1\n",
       "2  PAURA E DELIRIO ALLA CNN: IL MINISTERO DELLA V...               1\n",
       "3  L'Aspirina non aumenta la sopravvivenza dei pa...               0\n",
       "4  L'Italia non puo' dare armi lo vieta la Costit...               0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1845 entries, 0 to 1844\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   comment_text    1842 non-null   object\n",
      " 1   conspiratorial  1845 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 29.0+ KB\n"
     ]
    }
   ],
   "source": [
    "texts_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>conspiratorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    comment_text  conspiratorial\n",
       "244          NaN               0\n",
       "263          NaN               0\n",
       "665          NaN               0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df[texts_df['comment_text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = texts_df[texts_df.comment_text.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1842 entries, 0 to 1844\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   comment_text    1842 non-null   object\n",
      " 1   conspiratorial  1842 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 43.2+ KB\n"
     ]
    }
   ],
   "source": [
    "texts_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    925\n",
       "0    917\n",
       "Name: conspiratorial, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df.conspiratorial.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove break line characthers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df.comment_text = texts_df.comment_text.apply(lambda text: text.replace('\\n\\n', ' ').replace('\\n', ' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "80-20 train-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing datasets using stratified sampling\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, eval_index in split.split(texts_df, texts_df.conspiratorial):\n",
    "    train_df, val_df = texts_df.iloc[train_index], texts_df.iloc[eval_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1473 entries, 1512 to 1771\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   comment_text    1473 non-null   object\n",
      " 1   conspiratorial  1473 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 34.5+ KB\n",
      "None\n",
      "1    740\n",
      "0    733\n",
      "Name: conspiratorial, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.info())\n",
    "print(train_df.conspiratorial.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 369 entries, 363 to 670\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   comment_text    369 non-null    object\n",
      " 1   conspiratorial  369 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 8.6+ KB\n",
      "None\n",
      "1    185\n",
      "0    184\n",
      "Name: conspiratorial, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(val_df.info())\n",
    "print(val_df.conspiratorial.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-italian-xxl-cased', do_lower_case=False)\n",
    "\n",
    "texts_tr = train_df['comment_text']\n",
    "labels_tr = train_df['conspiratorial'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_tr = train_df['comment_text']\n",
    "labels_tr = train_df['conspiratorial'].to_numpy()\n",
    "\n",
    "texts_val = val_df['comment_text']\n",
    "labels_val = val_df['conspiratorial'].to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe distribution of tokenized texts lengths by trying a simple tokenization on both tr and val sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (526 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_len_list = []\n",
    "\n",
    "for sentence in texts_tr:\n",
    "    input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    tokenized_len_list.append(len(input_ids))\n",
    "for sentence in texts_val:\n",
    "    input_ids = tokenizer.encode(sentence, add_special_tokens=True)\n",
    "    tokenized_len_list.append(len(input_ids))\n",
    "\n",
    "sns.displot(tokenized_len_list)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum tokenized length is above the BERT max_lenght limit of 512. Very few texts are above this limit, so we truncate to 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/giacomo/mambaforge/envs/nlp/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "\n",
    "# Tr set\n",
    "input_ids_tr = []\n",
    "attention_masks_tr = []\n",
    "\n",
    "# `encode_plus` will:\n",
    "#   1. Tokenize the sentence, 2. Prepend the `[CLS]` token to the start, 3. Append the `[SEP]` token to the end\n",
    "#   4. Map tokens to their IDs, 5. Pad or truncate the sentence to `max_length`, 6. Create attention masks for [PAD] tokens\n",
    "\n",
    "for sentence in texts_tr:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 512,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence and attention mask to the list.    \n",
    "    input_ids_tr.append(encoded_dict['input_ids'])\n",
    "    attention_masks_tr.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Val set\n",
    "input_ids_val = []\n",
    "attention_masks_val = []\n",
    "\n",
    "for sentence in texts_val:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sentence,\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 512,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence and attention mask to the list.    \n",
    "    input_ids_val.append(encoded_dict['input_ids'])\n",
    "    attention_masks_val.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists into tensors\n",
    "\n",
    "input_ids_tr = torch.cat(input_ids_tr, dim=0)\n",
    "input_ids_val = torch.cat(input_ids_val, dim=0)\n",
    "\n",
    "attention_masks_tr = torch.cat(attention_masks_tr, dim=0)\n",
    "attention_masks_val = torch.cat(attention_masks_val, dim=0)\n",
    "\n",
    "labels_tr = torch.tensor(labels_tr)\n",
    "labels_val = torch.tensor(labels_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap data into a TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = TensorDataset(input_ids_tr, attention_masks_tr, labels_tr)\n",
    "val_dataset = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataLoader needs to know our batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the DataLoaders for our training and validation sets. Tr samples are taken in random order, while validation are taken sequentially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataloader = DataLoader(tr_dataset, sampler=RandomSampler(tr_dataset), batch_size = batch_size)\n",
    "\n",
    "val_dataloader = DataLoader(val_dataset, sampler=SequentialSampler(val_dataset), batch_size = batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rate = 3e-5\n",
    "scheduler_warmup_step = 0\n",
    "max_epochs = 20\n",
    "\n",
    "# Num batches*num epochs\n",
    "tr_steps = len(tr_dataloader)*max_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0 were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/giacomo/mambaforge/envs/nlp/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3080 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "bert_clf_model, loss_function, optimizer, scheduler, device = init_bert_clf(tr_steps=tr_steps, lr_rate=lr_rate, scheduler_warmp_steps=scheduler_warmup_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using as device:', device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-21 12:30:32.611595\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "curr_date = datetime.now()\n",
    "\n",
    "print(datetime.now())\n",
    "\n",
    "save_folder_pth = './bert_subtaskA/{}_{}_{}-{}.{}'.format(curr_date.day, curr_date.month, curr_date.day, curr_date.hour, curr_date.minute)\n",
    "if(not path.exists(save_folder_pth)):\n",
    "    os.mkdirs(save_folder_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_optimizer = optimizer\n",
    "curr_scheduler = scheduler\n",
    "curr_bert_clf = bert_clf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch_i in tqdm(range(max_epochs)):\n",
    "    # Train\n",
    "    avg_epoch_loss_tr, acc_score_tr, f1_score_tr, model, optimizer, scheduler = train_bert_clf(bert_clf_model, tr_dataloader, loss_function, optimizer, scheduler, device)\n",
    "    curr_optimizer = optimizer\n",
    "    curr_scheduler = scheduler\n",
    "    curr_bert_clf = model\n",
    "    \n",
    "    print('Epoch: {}| Tr Loss: {} - Tr acc: {} - Tr f1: {}'.format(epoch_i, avg_epoch_loss_tr, acc_score_tr, f1_score_tr))\n",
    "\n",
    "    # Eval\n",
    "    avg_epoch_loss_val, acc_score_val, f1_score_val, predictions, labels = eval_bert_clf(bert_clf_model, val_dataloader, loss_function, device)\n",
    "    print('EVALUATION | Val Loss: {} - Val acc: {} - Val f1: {}'.format(avg_epoch_loss_val, acc_score_val, f1_score_val))\n",
    "\n",
    "    # Save\n",
    "    save_path = os.path.join(save_folder_pth, 'bert_clf.pt')\n",
    "    torch.save({\n",
    "                'epoch': epoch_i,\n",
    "                'model_state_dict': curr_bert_clf.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'schdeduler_state_dict': scheduler.state_dict(),\n",
    "                'tr_loss': avg_epoch_loss_tr,\n",
    "                'val_loss': avg_epoch_loss_val,\n",
    "                'tr_acc': acc_score_tr,\n",
    "                'val_acc': acc_score_val,\n",
    "                'tr_f1': f1_score_tr,\n",
    "                'val_f1': f1_score_val,\n",
    "                'val_preds': predictions\n",
    "                }, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
