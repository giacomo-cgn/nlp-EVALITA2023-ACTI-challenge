{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subtask A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = pd.read_csv('subtaskA_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>conspiratorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>⚡Se non ci fossero soldati non ci sarebbero gu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21/08/21]( [PRE-PRINT]\\n\\n📄__ \"Shedding of Inf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PAURA E DELIRIO ALLA CNN: IL MINISTERO DELLA V...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L'Aspirina non aumenta la sopravvivenza dei pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L'Italia non puo' dare armi lo vieta la Costit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  conspiratorial\n",
       "0  ⚡Se non ci fossero soldati non ci sarebbero gu...               0\n",
       "1  21/08/21]( [PRE-PRINT]\\n\\n📄__ \"Shedding of Inf...               1\n",
       "2  PAURA E DELIRIO ALLA CNN: IL MINISTERO DELLA V...               1\n",
       "3  L'Aspirina non aumenta la sopravvivenza dei pa...               0\n",
       "4  L'Italia non puo' dare armi lo vieta la Costit...               0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1845 entries, 0 to 1844\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   comment_text    1842 non-null   object\n",
      " 1   conspiratorial  1845 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 29.0+ KB\n"
     ]
    }
   ],
   "source": [
    "texts_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>conspiratorial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    comment_text  conspiratorial\n",
       "244          NaN               0\n",
       "263          NaN               0\n",
       "665          NaN               0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df[texts_df['comment_text'].isna()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete rows with NaN text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_df = texts_df[texts_df.comment_text.notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1842 entries, 0 to 1844\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   comment_text    1842 non-null   object\n",
      " 1   conspiratorial  1842 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 43.2+ KB\n"
     ]
    }
   ],
   "source": [
    "texts_df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count positive and negatie samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    925\n",
       "0    917\n",
       "Name: conspiratorial, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_df.conspiratorial.value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing datasets using stratified sampling\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, eval_index in split.split(texts_df, texts_df.conspiratorial):\n",
    "    train_df, eval_df = texts_df.iloc[train_index], texts_df.iloc[eval_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1473 entries, 1512 to 1771\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   comment_text    1473 non-null   object\n",
      " 1   conspiratorial  1473 non-null   int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 34.5+ KB\n",
      "None\n",
      "1    740\n",
      "0    733\n",
      "Name: conspiratorial, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_df.info())\n",
    "print(train_df.conspiratorial.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 369 entries, 363 to 670\n",
      "Data columns (total 2 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   comment_text    369 non-null    object\n",
      " 1   conspiratorial  369 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 8.6+ KB\n",
      "None\n",
      "1    185\n",
      "0    184\n",
      "Name: conspiratorial, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(eval_df.info())\n",
    "print(eval_df.conspiratorial.value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset seems balanced in term of positive and negative samples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = [\"text\", \"labels\"]\n",
    "eval_df.columns = [\"text\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "print(cuda_available)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other models\n",
    "\n",
    "# model = ClassificationModel(\"bert\", \"dbmdz/bert-base-italian-cased\", args=model_args, use_cuda=cuda_available)\n",
    "# model = ClassificationModel(\"distilbert\", \"indigo-ai/BERTino\", args=model_args, use_cuda=cuda_available) --- 0.81 with 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each epoch will have 185 steps.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "\n",
    "# Num steps in epoch = num training samples / batch size\n",
    "steps_per_epoch = int(np.ceil(len(train_df) / float(batch_size)))\n",
    "\n",
    "print('Each epoch will have {:,} steps.'.format(steps_per_epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-italian-xxl-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-italian-xxl-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Optional model configuration\n",
    "model_args = ClassificationArgs(num_train_epochs=20, do_lower_case=False, evaluate_during_training=True, evaluate_during_training_verbose=True, # Main options\n",
    "                                use_multiprocessing=False, use_multiprocessing_for_evaluation=False, overwrite_output_dir=True, # System configurations\n",
    "                                eval_batch_size=batch_size, train_batch_size=batch_size, evaluate_during_training_steps=steps_per_epoch, # Batch sizes and steps\n",
    "                                use_early_stopping=True, early_stopping_metric='eval_loss', early_stopping_patience=2, early_stopping_metric_minimize=True, # Early stopping\n",
    "                                early_stopping_delta=0.001, early_stopping_consider_epochs=True\n",
    "                                   )\n",
    "\n",
    "# Create a ClassificationModel\n",
    "\n",
    "model = ClassificationModel(\"bert\", \"dbmdz/bert-base-italian-xxl-cased\", args=model_args, use_cuda=cuda_available)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_train_bert_128_2_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e6cd971a904b489e43c4c9408a0e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94df59574943441d989d676693884df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 20:   0%|          | 0/185 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giacomo/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_2_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.5077451753055425, 'tp': 98, 'tn': 172, 'fp': 12, 'fn': 87, 'auroc': 0.8576674500587544, 'auprc': 0.8684350593246475, 'eval_loss': 0.5314895142900183}\n",
      "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.classification.classification_model: Current step: 1\n",
      "INFO:simpletransformers.classification.classification_model: Early stopping patience: 2\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_2_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.5077451753055425, 'tp': 98, 'tn': 172, 'fp': 12, 'fn': 87, 'auroc': 0.8576674500587544, 'auprc': 0.8684350593246475, 'eval_loss': 0.5314895142900183}\n",
      "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.classification.classification_model: Current step: 2\n",
      "INFO:simpletransformers.classification.classification_model: Early stopping patience: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d97be0abb8c49fe93cf073a565f4623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 20:   0%|          | 0/185 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_2_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.5741834457642736, 'tp': 125, 'tn': 163, 'fp': 21, 'fn': 60, 'auroc': 0.8949471210340775, 'auprc': 0.892329266999466, 'eval_loss': 0.47875352616005756}\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_2_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.5741834457642736, 'tp': 125, 'tn': 163, 'fp': 21, 'fn': 60, 'auroc': 0.8949471210340775, 'auprc': 0.892329266999466, 'eval_loss': 0.47875352616005756}\n",
      "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.classification.classification_model: Current step: 1\n",
      "INFO:simpletransformers.classification.classification_model: Early stopping patience: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a778dfa2a17e4a31ad1c26b71a08b82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 20:   0%|          | 0/185 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_2_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.6167792016199172, 'tp': 143, 'tn': 155, 'fp': 29, 'fn': 42, 'auroc': 0.8878231492361927, 'auprc': 0.8908460260651492, 'eval_loss': 0.9220846434856983}\n",
      "INFO:simpletransformers.classification.classification_model: No improvement in eval_loss\n",
      "INFO:simpletransformers.classification.classification_model: Current step: 2\n",
      "INFO:simpletransformers.classification.classification_model: Early stopping patience: 2\n",
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_2_2\n",
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.6167792016199172, 'tp': 143, 'tn': 155, 'fp': 29, 'fn': 42, 'auroc': 0.8878231492361927, 'auprc': 0.8908460260651492, 'eval_loss': 0.9220846434856983}\n",
      "INFO:simpletransformers.classification.classification_model: Patience of 2 steps reached\n",
      "INFO:simpletransformers.classification.classification_model: Training terminated.\n",
      "INFO:simpletransformers.classification.classification_model: Training of bert model complete. Saved to outputs/.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(555,\n",
       " defaultdict(list,\n",
       "             {'global_step': [185, 185, 370, 370, 555, 555],\n",
       "              'train_loss': [1.3037109375,\n",
       "               1.3037109375,\n",
       "               1.98046875,\n",
       "               1.98046875,\n",
       "               0.0024662017822265625,\n",
       "               0.0024662017822265625],\n",
       "              'mcc': [0.5077451753055425,\n",
       "               0.5077451753055425,\n",
       "               0.5741834457642736,\n",
       "               0.5741834457642736,\n",
       "               0.6167792016199172,\n",
       "               0.6167792016199172],\n",
       "              'tp': [98, 98, 125, 125, 143, 143],\n",
       "              'tn': [172, 172, 163, 163, 155, 155],\n",
       "              'fp': [12, 12, 21, 21, 29, 29],\n",
       "              'fn': [87, 87, 60, 60, 42, 42],\n",
       "              'auroc': [0.8576674500587544,\n",
       "               0.8576674500587544,\n",
       "               0.8949471210340775,\n",
       "               0.8949471210340775,\n",
       "               0.8878231492361927,\n",
       "               0.8878231492361927],\n",
       "              'auprc': [0.8684350593246475,\n",
       "               0.8684350593246475,\n",
       "               0.892329266999466,\n",
       "               0.892329266999466,\n",
       "               0.8908460260651492,\n",
       "               0.8908460260651492],\n",
       "              'eval_loss': [0.5314895142900183,\n",
       "               0.5314895142900183,\n",
       "               0.47875352616005756,\n",
       "               0.47875352616005756,\n",
       "               0.9220846434856983,\n",
       "               0.9220846434856983]}))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.train_model(train_df, eval_df=eval_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n",
      "INFO:simpletransformers.classification.classification_utils: Saving features into cached file cache_dir/cached_dev_bert_128_2_2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40877392e42c4beabcd8442947b994ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Evaluation:   0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_model:{'mcc': 0.6167792016199172, 'tp': 143, 'tn': 155, 'fp': 29, 'fn': 42, 'auroc': 0.8878231492361927, 'auprc': 0.8908460260651492, 'eval_loss': 0.9220846434856983}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mcc': 0.6167792016199172, 'tp': 143, 'tn': 155, 'fp': 29, 'fn': 42, 'auroc': 0.8878231492361927, 'auprc': 0.8908460260651492, 'eval_loss': 0.9220846434856983}\n",
      "[{'guid': 10, 'text_a': \"\\nLetters scritta dalla ditta.ssa Gatti a Robert Kennedy jr. Per spiegargli la situazione in Italia oggi.\\nC'è sia il testo originale in inglese che la traduzione.\", 'text_b': None, 'label': 1}, {'guid': 15, 'text_a': \"In breve tempo, per accedere a Internet, sarà richiesto un documento d'identità Digitale.\", 'text_b': None, 'label': 1}, {'guid': 18, 'text_a': 'Bisogna proprio dirlo: questi NO-VAX seminano odio ovunque e sono dei teppisti.\\n[🇮🇹', 'text_b': None, 'label': 0}, {'guid': 19, 'text_a': '\"EBBASTAAA\"\\n\\n', 'text_b': None, 'label': 0}, {'guid': 20, 'text_a': 'Si, penso ai bambini vaccinati e più in generale a tutti quelli che non hanno avuto una reale scelta per un motivo o per un altro, senza entrare nel merito del perché o per come', 'text_b': None, 'label': 1}, {'guid': 31, 'text_a': \"Israele sembra essere entrata in una crisi politica permanente. Il governo Bennett dopo appena un anno di vita è già caduto, ed è caduto su una delle questioni vitali della politica del Paese, quella che riguarda la Cisgiordania. La Cisgiordania è il territorio nel quale vivono molti palestinesi e Israele la occupa dal 1967. Su questo territorio, esistono due leggi in omaggio ai principi dell'apartheid sionista. Una che prevede un trat di favore per i coloni israeliani e un'altra che prevede la legge marziale per i nativi palestinesi. Il Parlamento avrebbe dovuto rinnovare questa legge che discrimina il popolo palestinese a luglio, ma il Parlamento israeliano, la Knesset, sembra essere diviso sulla questione. \\n\\nC'è chi come Bennett vorrebbe definitivamente annettere la Cisgiordania a Israele, ma questo significherebbe ritrovarsi in minoranza perché i palestinesi hanno una crescita demografica maggiore degli israeliani. C'è chi invece vorrebbe lasciare la Cisgiordania ai palestinesi ma i falchi come Bennett e Netanyahu sono contrari. Israele quindi sta vivendo una contraddizione che mette a rischio la sua stessa esistenza come entità statuale. Una contraddizione nata per volontà della famiglia Rothschild che ordinò alla Gran Bretagna nel 1917 di procedere alla creazione di uno stato non voluto dagli ebrei ma piuttosto dalla lobby sionista. Sembra che siamo giunti all'implosione di questa insanabile contraddizione. Lo stato eletto dal Nuovo Ordine Mondiale rischia di non sopravvivere a questa crisi che riguarda le radici della sua stessa creazione. \\n\", 'text_b': None, 'label': 1}, {'guid': 32, 'text_a': '11 settembre: la madre di tutti i complottismi\\n\\n', 'text_b': None, 'label': 0}, {'guid': 34, 'text_a': \"Grandissimo successo delle iniziative NO GP in tutte le piazze d'italia: aperitivi vino e pasticcini ovunque.\\nQuesta è Forlì sabato pomeriggio-sera\\n\\n[🇮🇹]( \", 'text_b': None, 'label': 1}, {'guid': 37, 'text_a': 'Le testimonianze, a che se rese con il sorriso, a volte sono amare.\\nCome si fa a non vedere una regia unica per tutto questo?\\n\\n🇮🇹 ', 'text_b': None, 'label': 1}, {'guid': 45, 'text_a': \"Ma c'è qualcuno qui che non si fida della scienza e degli scienziati?\\n[🇮🇹 \", 'text_b': None, 'label': 0}, {'guid': 52, 'text_a': '❗️**Ecco perché ci hanno forzati agli arresti domiciliari a tutti, per farci ammalare.**\\n\\n', 'text_b': None, 'label': 1}, {'guid': 55, 'text_a': \"20/11/2021 il Mattino web\\n«Covid, pericolo concreto di nuove restrizioni e chi è vaccinato non ha l'immunità»\\n(no spe...restrizioni per tutti e chi è vaccinato non è salvo?)\", 'text_b': None, 'label': 0}, {'guid': 59, 'text_a': 'Secondo gli sms trapelati dal laptop, gli affari redditizi di Hunter spesso includevano la donazione fino anche al 50% dei suoi guadagni a suo padre Joe.', 'text_b': None, 'label': 1}, {'guid': 60, 'text_a': 'Quante volte abbiamo visto la luna.. nel cielo.. in pieno giorno..?  Io tante volte..', 'text_b': None, 'label': 1}, {'guid': 64, 'text_a': '**REGNO UNITO: DIETROFRONT SUL VACCINO A DONNE INCINTE: \"È SCONSIGLIATO\"\\n\\n**Pubblicate sul sito governativo del **Regno Unito** le nuove linee guida riguardo alla somministrazione del vaccino di **Pfizer**. Dopo averlo \"for raccomandato\" alle **donne incinte**, le autorità fanno ora dietrofront: \"è sconsigliato\". \\n\\n➡️**__ **__**__', 'text_b': None, 'label': 0}, {'guid': 67, 'text_a': \"Verso le 06:00 ora di Mosca, le truppe ucraine sono sbarcate sulla costa del bacino di Kakhovka, tre chilometri a nord-est della centrale nucleare di Zaporozhye, con due gruppi di sabotaggio composti da un massimo di 60 persone su sette imbarcazioni e hanno tentato di impossessarsi della centrale - Ministero della Difesa russo\\nLa provocazione del regime di Kiev con lo sbarco è finalizzata a disturbare l'arrivo del gruppo di lavoro dell'AIEA alla centrale nucleare di Zaporozhye, ha dichiarato il Ministero della Difesa russo. Il dipar ha aggiunto che 4 proiettili ucraini sono esplosi durante il bombardamento a una distanza di 400 metri dalla prima unità di potenza della ZNPP.\\n\\n\", 'text_b': None, 'label': 1}, {'guid': 74, 'text_a': 'Deve spurgare. Come si usa fare con le lumache prima di essere mangiate...... Questa si chiama anche fame di vendetta', 'text_b': None, 'label': 0}, {'guid': 75, 'text_a': \"Salve a tutti. Il nostro studio professionale, Vinciprova & Chinnici, con sede a Catania, si occupa da tempo della questione vaccinale, in particolare, dell'obbligo giuridico imposto dal legislatore ed attualmente applicabile alla professione sanitaria e non solo \\nI recenti risvolti giudiziari, hanno esitato risultati positivi, come ad es. accade in relazione alla durata del differimento dell'obbligo, in ipotesi di guarigione.\\nEbbene, siamo disponibili ad effettuare, GRATUITAMENTE, sessioni da remoto, per rispondere alle Vostre domande.\\n\\nPer info scrivete a vincenzo.vinciprova.eu\\nOppure su fpaoloa.it\\n\\nAvv. Favazza Paolo Andrea\\n\\nNo pubblicità commerciale\", 'text_b': None, 'label': 1}, {'guid': 78, 'text_a': 'Come Hitler ha manipolato 60 milioni di normalissime persone in pochi anni? Rincoglionito\\n\\nMetti in funzione quel cervellino bruciato dalla droga', 'text_b': None, 'label': 0}, {'guid': 79, 'text_a': 'sentinel 5p fa immagini meteo e quindi lasciamo stare', 'text_b': None, 'label': 1}, {'guid': 80, 'text_a': 'Perché è femmina allora nn va bene ? A quanto pare i trogloditi non si sono ancora estinti!!', 'text_b': None, 'label': 0}, {'guid': 81, 'text_a': 'I nodi vengono al pettine anche per la **\"Legione straniera\"** che combatte per il regime di Kiev.\\n \\n**Molti dei \"volontari\" denunciano che i comandanti dell\\'unità sono implicati in saccheggi, molestie sessuali, aggressioni e invio di soldati impreparati in missioni suicide.\\n**\\nNon si tratta di voci raccolte da blogger filo-russi, bensì di un\\'[inchiesta del Kyiv Independent.]( \\n\\nSi punta l\\'indice in particolare su uno dei comandanti - il polacco **Piotr Kapuściński** - membro di un\\'organizzazione criminale in patria, dove è ricercato per frode. \\n\\nI \"volontari\" stranieri lo hanno accusato di gravi abusi di potere, per aver ordinato di saccheggiare negozi, minacciato i subalterni con una pistola e molestato sessualmente le dottoresse e le infermiere aggregate alla Legione. \\n\\nSecondo il Kyiv Independent, un rapporto su tali crimini è stato presentato al parlamento ucraino e testimonianze scritte sono state inviate anche a Zelensky.', 'text_b': None, 'label': 1}, {'guid': 92, 'text_a': 'Podcast – Mettere in lockdown i non vaccinati forse non basta\\n\\n', 'text_b': None, 'label': 0}, {'guid': 93, 'text_a': 'Essere baby Sitter, studente, dottore, scienziato,tronista non cambia le idee, le cambiano i fatti\\nNon per nulla settimana scorsa il ministro Speranza, ha respinto i vaccinati colpiti da effetti collaterali allontanandoli e lasciandoli senza risposte\\n\\nPerò è più bello farsi bucare che aumenta problemi e non risolve gli attuali', 'text_b': None, 'label': 0}, {'guid': 106, 'text_a': 'Andrology • 17/06/22](\\n\\n📃 \"__Covid-19 vaccination BNT162b2 temporarily impairs semen concentration and total motile count among semen donors\"\\n🇮🇹 \"**LA VACCINAZIONE COVID-19 BNT162B2 [PFIZER] ALTERA TEMPORANEAMENTE LA CONCENTRAZIONE DI SPERMA E LA CONTA MOBILE TOTALE [DEGLI SPERMATOZOI] TRA I DONATORI DI SEME__**\"\\n\\n⚠️ \"Lo sviluppo delle vaccinazioni contro il Covid-19 rappresenta un notevole risultato scientifico. Tuttavia **sono state sollevate preoccupazioni riguardo al loro possibile impatto negativo sulla fertilità maschile.**\"\\n\\n✅ \"OBIETTIVO: studiare l\\'effetto del vaccino Covid-19 BNT162b2 (Pfizer) sui parametri dello sperma tra i donatori di sperma (SD).\"\\n\\n📊 \"37 donatori di sperma provenienti da tre banche del seme hanno fornito 220 campioni che sono stati inclusi in questo studio di coorte [...]. **Lo studio comprendeva quattro fasi**:\\n• **T0**: controllo basale pre-vaccinazione [...]; \\n• **T1, T2 e T3**: valutazioni rispettivamente a **breve, medio e lungo termine**. Ciascuna includeva 1-3 campioni di sperma per donatore forniti rispettivamente 15-45, 75-120 e oltre 150 giorni dopo il comple della vaccinazione [che consisteva in sole 2 dosi, ndt].\"\\n\\n📊 \"RISULTATI: le misurazioni ripetitive **hanno rivelato una diminuzione della concentrazione spermatica del 15,4% al T2 [medio termine] portando a una riduzione della conta mobile totale del 22,1% (...) rispetto a T0 **[prevaccinazione]. [...] La valutazione T3 ha dimostrato un recupero generale.\"\\n\\n❗️\"Questo studio longitudinale incentrato sui donatori di sperma dimostra la concentrazione selettiva e temporanea degli spermatozoi e il deterioramento della TMC [conta degli spermatozoi mobili totali] tre mesi dopo la vaccinazione, seguiti da un successivo recupero verificato da diverse analisi statistiche.\"\\n\\n📚 **', 'text_b': None, 'label': 0}, {'guid': 109, 'text_a': \"L'ex presidente dell'Ucraina Poroshenko ha affermato che un tempo aveva accettato gli accordi di Minsk per prendersi la pausa necessaria per preparare l'esercito ucraino a una guerra futura. La confessione è utile.\\n\\nIn primo luogo, conferma l'esistenza di una strategia a lungo termine per la militarizzazione dell'Ucraina. Lo sapevano già tutti. Forse alcuni degli idealisti occidentali credevano che il presidente dell'Ucraina stesse andando agli accordi di Minsk per amore della pace. Fin dall'inizio, da parte russa si era capito che Poroshenko avrebbe sfruttato la pausa, i cui garanti erano Germania e Francia. Diplomatici ed esperti tedeschi e francesi sapevano che la parte ucraina li stava prendendo per il naso. Ma hanno preferito ignorarlo. Ora, dopo aver pubblicamente riconosciuto l'ovvio, Poroshenko ha reso evidente a tutti che i team della Merkel e dell'Olanda erano o sciocchi o bugiardi.  A voi la scelta.\\n\\nIn secondo luogo, Poroshenko ha fornito un'altra prova delle parole di Putin secondo cui l'Ucraina avrebbe attaccato il Donbas per tutti questi anni. Politici e funzionari ucraini di vario livello hanno ripetu confermato questo obiettivo. Ma questa è la prima volta che lo fa francamente l'ex capo di Stato. Ora sarà difficile confutare l'esistenza di una strategia di aggressione e di piani concreti per attaccare il Donbass e la Crimea.\\n\\nIn terzo luogo, Poroshenko fornisce argomenti a favore del fatto che, dopo il comple dell'operazione militare, i negoziati con l'Ucraina possono essere condotti solo dal punto di vista della necessità della sua smilitarizzazione e della assicurazione di garanzie politiche che questa smilitarizzazione non sarà violata. Non si accettano dichiarazioni a vanvera sullo status neutrale dell'Ucraina.\", 'text_b': None, 'label': 1}, {'guid': 121, 'text_a': 'Comitato tecnico scientifico verso lo SCOGLIMENTO 😭😭\\n\\n', 'text_b': None, 'label': 0}, {'guid': 124, 'text_a': 'COVID: su quali vaccini si sta lavorando?', 'text_b': None, 'label': 0}, {'guid': 135, 'text_a': 'Prof. Stefano Scoglio: vi spiego perché il covid non esiste', 'text_b': None, 'label': 1}, {'guid': 138, 'text_a': 'Tic toc tic toc... Gli esperti di giustizia della CDU/CSU chiedono nuove perquisizioni per il cancelliere Olaf Scholz (64 anni, SPD)\\n\\nIl motivo è l\\'affare Warburg, che riguarda le donazioni del partito alla SPD e i milioni di soldi delle tasse regalati durante il suo mandato di sindaco di Amburgo.\\n\\nI procuratori di Colonia hanno notato nei fascicoli che ci sono indicazioni di \"cancellazioni mirate\" di voci del calendario nel complesso Warburg.\\n\\nFinora è stata cercata solo la casella di posta elettronica ufficiale del sindaco Scholz. La vicepresidente del gruppo parlamentare CDU/CSU Andrea Lindholz (51, CSU): \"Scholz deve ora rivelare agli inquirenti anche la sua corrispondenza privata via e-mail\".\\n\\nIl caso riguarda gli anni dal 2014 in poi in cui lo Stato di Amburgo si è astenuto dal riscuotere 47 milioni di euro di tasse dalla Warburg Bank. I messaggi WhatsApp, i messaggi di testo e le e-mail private saranno oggetto di indagine. Banchieri, avvocati e investitori hanno frodato allo Stato tedesco miliardi di euro con trucchi fiscali e operazioni azionarie dal 2001 al 2016. In queste cosiddette transazioni Cum-Ex, sono state rimborsate due volte imposte che erano state pagate una sola volta.\\n\\nEra coinvolta anche la banca Warburg di Amburgo. Si sta indagando sul ruolo svolto dall\\'allora sindaco Olaf Scholz. ', 'text_b': None, 'label': 1}, {'guid': 145, 'text_a': 'Ma perché ci è andato??? Perché non ha usato cure alternative???', 'text_b': None, 'label': 1}, {'guid': 146, 'text_a': 'Pertanto terra sferica colpita e affondata', 'text_b': None, 'label': 1}, {'guid': 155, 'text_a': 'Conclusione la luna ha il diametro di 1.6km e ruota ad una quota di 200km', 'text_b': None, 'label': 0}, {'guid': 167, 'text_a': 'Due anni Delta piuttosto rilevante.\\nIl 21 ci sarà la decisione della FED sui tassi d’interesse, 23/24/25 date da seguire con attenzione per via delle tante coincidenze descritte nelle ultime due settimane. WWG1WGA', 'text_b': None, 'label': 1}, {'guid': 177, 'text_a': '#Wimbledon \\n\\nNole Djokovic, pur essendo non vaccinato e quindi morto come tutti i non vaccinati entro marzo del 2022 (cit)  conquista il 7° titolo senza accasciarsi subito dopo per un malore improvviso.', 'text_b': None, 'label': 0}, {'guid': 186, 'text_a': 'Trump sulla possibilità di essere incriminato:\\n\"Non credo che il popolo degli Stati Uniti lo sosterrebbe... avresti problemi in questo paese come non li abbiamo mai visti prima... non credo che sopporterebbero per questo... soprattutto perché sanno che sono totalmente innocente.\" 👀\\n\\n\\n\\n ', 'text_b': None, 'label': 1}, {'guid': 191, 'text_a': '**Donbass, terzo giorno di referendum.** Anche oggi i bombardamenti fanno da colonna sonora.\\n\\nSe qualcuno crede davvero che la gente qui abbia paura di votare e lo faccia perché terrorizzata da un fucile in spalla ad un poliziotto, probabilmente nemmeno ha idea di come viva questa città da 8 anni. \\n\\nNon sa che in alcuni quartieri gli scrutatori indossano giubbotti antiproiettile, e non certo per paura di questi fucili. Non sa che sono nelle scorse due settimane una cinquantina di civili sono rimasti uccisi dai colpi dell’artiglieria ucraina (la maggior parte delle vittime sono morte in centro città, da parte al teatro o al mercato, lontano dal fronte e/o obiettivi militari). \\n\\nNon lo sa perché gli stessi giornalisti che trovano scandaloso il fatto che i poliziotti girino con un AK a tracolla si guardano bene dal raccontare queste stragi. Stando nei loro comodi uffici non si preoccupano di cercare la verità, limitandosi a prender per Vangelo le dichiarazioni diffuse su Twitter da qualche amico di Zelensky.', 'text_b': None, 'label': 1}, {'guid': 193, 'text_a': '__**\"IL DOVERE DI ISTRUIRSI\" __** \\nPerò Pregliasco questo non sembra averlo capito ancora bene: dovrebbe  \"ripassarlo\" prima di esprimere pareri pubblici... come ha fatto qui: ', 'text_b': None, 'label': 0}, {'guid': 200, 'text_a': '29/10/21]( [Case report]\\n\\n📄 __\"Anaphylaxis after Moderna COVID-19 vaccine\"\\n🇮🇹 \"Anafilassi dopo il vaccino Moderna COVID-19\"__\\n\\n📊 \"L\\'[ACAAI]( COVID-19 Task Force__ raccomanda [...] chiunque riceva il vaccino dovrebbe essere sottoposto a controlli per il possibile rischio di reazione allergica al vaccino mRNA COVID-19.\"\\n⚠️ \"**se un paziente ha una grave reazione allergica entro 4 ore dalla prima dose di Moderna o Pfizer-BioNTech, non dovrebbe ricevere la seconda dose**. [...] La maggior parte delle reazioni anafilattiche si verifica entro i primi 15 minuti dall\\'iniezione. **I vaccini Moderna o Pfizer-BioNTech non devono essere somministrati a soggetti che hanno una storia nota di reazione allergica a qualsiasi componente del vaccino.** La componente specifica del vaccino non è stata ancora identificata; tuttavia il [PEG]( è uno degli ingredienti dei vaccini mRNA noti per causare anafilassi. [...] **coloro che ne sono allergici avranno una reazione grave o addirittura fatale**.\"', 'text_b': None, 'label': 1}, {'guid': 208, 'text_a': 'Ecco il computer che dichiarano di aver usato per tutti i calcoli e correzioni di volo', 'text_b': None, 'label': 1}, {'guid': 210, 'text_a': \"ma come ho detto solo un sole a parabola.. puo' giustificare la teoria del modello sferico\", 'text_b': None, 'label': 0}, {'guid': 230, 'text_a': '[Rumble](', 'text_b': None, 'label': 1}, {'guid': 233, 'text_a': 'Bisogna cercare anche i medici vaccinatori, ospedale dove operano e abitazione', 'text_b': None, 'label': 1}, {'guid': 234, 'text_a': 'Che figura di 💩...\\nAttacco hacker a Regione Lazio, con intrusione cryptolocker.....\\nE chiamano l\\'FBI per cercare dei marocchini o dei senegalesi che fanno truffe informatiche, spacciandole per hacker no vax!\\nD\\'Amato  \"tutti i dati dell\\'anagrafe vaccinale sono in nostro possesso\"....\\nSicuramente è vero, ma tutti cryptati!\\n😂😂😂😂\\nBasta pagare e risolvono tutto!\\n\\n🇮🇹 ', 'text_b': None, 'label': 0}, {'guid': 236, 'text_a': 'Biden ha dimenticato in quale paese si trova.\\n\\n\"Sono venuto in Arabia Saudita per aiutare a diffondere i nostri interessi\", ha detto parlando in Israele. 😂', 'text_b': None, 'label': 0}, {'guid': 244, 'text_a': 'Si, era un piccolo e chiuso account, si sospetta che abbia fatto mille post con date diverse e ieri abbia cancellato tutte le sbagliate(non si può modificare un Tweet su Twitter). Vi assicuro, per esperienza personale che ci sono account anonimi come Mr Pool(e molti altri) che, come faceva Q sulla board, danno continue “briciole” per decodificare la situazione.', 'text_b': None, 'label': 1}, {'guid': 254, 'text_a': 'Inizia a smontarsi anche la farsa del 6 Gennaio…\\n\\n', 'text_b': None, 'label': 1}, {'guid': 256, 'text_a': \"L'oggetto sferico nel video.. l'ho visto anche io a bassa quota sopra una penisola in Slovenia, purtroppo allora non esistevano i telefonini con tecnologia di oggi, per quei anni era gia' tanto scriversi un messaggio in sms .\", 'text_b': None, 'label': 1}, {'guid': 258, 'text_a': \"Questi sono i dati di ieri. In terapia intensiva sono piene al 10% vuol dire che ci sono ancora il 90% dei posti disponibili. Non ci sono gli ospedali in crisi. Nonostante questo Draghi protrae lo stato di emergenza. E' normale ?\\n\\n🇮🇹 \", 'text_b': None, 'label': 1}, {'guid': 265, 'text_a': '6) Negare le cure in case dai dottori, ma attenersi alla vigile attesa...', 'text_b': None, 'label': 1}, {'guid': 274, 'text_a': '🇺🇲🇺🇦 **Roger Waters, fondatore dei Pink Floyd, definisce Joe Biden un criminale di guerra **\\n\\nIl musicista, **in un\\'intervista per la CNN politics**, ha affermato che Biden continua ad accendere il fuoco del conflitto ucraino. “Questo è un crimine grave. Perché gli Stati Uniti non chiedono a Zelensky di avviare negoziati con Mosca per porre fine a questo terribile conflitto?\"\\n\\nRoger Waters ha anche sottolineato che l\\'operazione speciale per proteggere il Donbass è stata una reazione al tentativo di espandere la NATO fino ai confini della Russia, anche se l\\'organizzazione ha promesso di non farlo.\\n\\n\\n\\n 🎯 🎯 🎯', 'text_b': None, 'label': 1}, {'guid': 278, 'text_a': 'Non tutti gli Ukraini sono contro la Russia.\\n**Questa signora prende il microfono ad un militare che arruola per strada e non si fa mancare le parole.\\n**[🇮🇹 ', 'text_b': None, 'label': 1}, {'guid': 281, 'text_a': 'Panzana pazzesca del leghista Siri: le misure restrittive funzionano eccome\\n\\n', 'text_b': None, 'label': 1}, {'guid': 293, 'text_a': \"resta appunto il fatto che non e' chiaro cosa e' che scatena il virus ad essere piu aggressivo , indipenden dall'eta' della vittima\", 'text_b': None, 'label': 0}, {'guid': 295, 'text_a': '05/01/21](\\n\\n📄__ \"Herd Immunity to COVID-19: Alluring and Elusive\"\\n🇮🇹 \"Immunità di gregge per COVID-19: allettante e sfuggente\"__\\n\\n📊 \"Abbiamo davvero bisogno di un vaccino prima che una popolazione possa raggiungere l\\'immunità di gregge contro la COVID-19? La risposta prudente è sì, ma dobbiamo essere consapevoli che anche con il vaccino **probabilmente non raggiungeremo mai l\\'immunità di gregge**.\"\\n\\n📚 ', 'text_b': None, 'label': 0}, {'guid': 303, 'text_a': \"**❗️👍 Kazakistan si rifiuta di mandare suoi miliari ad ammazzare il popolo ucraino!\\n\\nE NON RICONOSCE L'INDIPENDENZA DEL DOMBASS OCCUPATO DAI RUSSI.\\n\\nTURCHIA HA BLOCCATO L'ACCESSO ALLE NAVI MILITARI RUSSE NEL MAR NERO.\\n\\nTUTTI CONTRO LO PSICOPATICO CRIMINALE PUTIN !**\", 'text_b': None, 'label': 0}, {'guid': 304, 'text_a': \"ho trovato questa penso la migliore.. bene aveva ragione l'ammiraglio Bird che diceva che L'Antartide e' molto piu vasto di quanto la mappa mostra...\", 'text_b': None, 'label': 1}, {'guid': 308, 'text_a': 'Matteo Gracis a Bologna alla manifestazione del gg 22, per chi non è potuto venire.\\nUn intervento carico di passione ed umanità, dove affiora la rabbia per la ricerca di risposte e di verità che ci vengono negate\\n\\n🇮🇹 ', 'text_b': None, 'label': 1}, {'guid': 309, 'text_a': 'Nel video.. visto e rivisto, non mi ero soffermato a questa affermazione di  Aldrin..  ma ora si', 'text_b': None, 'label': 0}, {'guid': 317, 'text_a': 'Consiglio questa lettura \"Zelensky salito al potere con un colpo di stato, guerra è tra Russia e NATO\", intervista a Luciano Canfora.', 'text_b': None, 'label': 1}, {'guid': 320, 'text_a': 'È mia opinione, atten ponderata, dato tutto ciò che sappiamo, che entrambe queste persone saranno incriminate penalmente dal consigliere speciale John Durham per aver pianificato e poi attuato una delle più massicce violazioni della sicurezza nazionale nella storia della gli Stati Uniti.\\n\\n', 'text_b': None, 'label': 1}, {'guid': 326, 'text_a': 'In Kazakistan non scherzano.\\nHanno problemi per il rincaro deil gas, noi abbiamo problemi con il rispetto della costituzione e per il lavoro.\\nDifficile dire quale sia il problema più grave.\\nNoi accontentiamoci di andare in piazza, anzi no, in piazza è vietato, bisogna andare negli spazi consentiti: i giardini pubblici di campagna lontano dai giochi per bimbetti.\\nSe bastasse un rosario da 5 minuti al giorno, saremmo tutti santi!\\necco il rosario:\\n \\n\\n[🇮🇹', 'text_b': None, 'label': 1}, {'guid': 329, 'text_a': 'Lo studio Pfizer suggerisce che il vaccino Covid-19 sia responsabile dell\\'enorme aumento di epatite tra i bambini mentre il governo del Regno Unito avvia un\\'indagine urgente\\n\\nL\\'UKHSA ha annunciato di aver rilevato alti tassi di infiammazione del fegato tra i bambini, ma ha escluso i virus comuni che causano l\\'epatite.\\n\\n\"La massima concentrazione media al di fuori del sito di iniezione è stata osservata nel fegato, equivalente al 21,5% della dose... sono stati osservati effetti epatici, compreso un ingrossamento del fegato\" - Studio Pfizer             ', 'text_b': None, 'label': 1}, {'guid': 338, 'text_a': '19/06/21]( [PRE-PRINT]\\n📎 [Clinical Infectious Diseases', 'text_b': None, 'label': 1}, {'guid': 341, 'text_a': 'Occupazione di spazi pubblici ,come quando eravamo a squola .loro hanno l obbligo di servizio pubblico', 'text_b': None, 'label': 0}, {'guid': 352, 'text_a': '**Biden offre vaccini alla Nord Corea: nessuna risposta.\\n**Gli Stati Uniti hanno “offerto vaccini” contro il Covid-19 alla Corea del Nord, che ha confermato il primo focolaio di coronavirus dall’inizio della pandemia, ma “non hanno avuto risposta”.\\n**Della serie \"come far diventare simpatico anche Kim Jong-un\"\\n**[🇮🇹 ', 'text_b': None, 'label': 0}, {'guid': 353, 'text_a': 'Quando si parla di esperti e di scienzah...', 'text_b': None, 'label': 0}, {'guid': 357, 'text_a': 'Bello sentire Trump che massacra Adolfino in tempi non sospetti\\n\\nTraduzione automatica \\n\\nPorca puttana... Trump sapeva che Putin si sarebbe trasferito in Ucraina con anni di anticipo... Trump e Putin hanno un\\'alleanza al 100%.\\n\\n Guardiamo indietro a questo scambio selvaggio del 25/09/2019.  Ha molto più senso di ciò di cui Trump stava parlando 2 anni fa in merito alla \"corruzione\" in Ucraina.\\n\\n Presta attenzione al linguaggio del corpo di Zelensky mentre Trump parla di Putin \"che risolve il problema dell\\'Ucraina\", in riferimento allo stato profondo e alla corruzione del DNC in Ucraina.\\n\\n Zelensky sembra aver visto un fantasma.  Se guardi l\\'intera intervista, si dimena per TUTTO il tempo.  Visualizzazione molto scomoda del linguaggio del corpo.  È così ovvio che anche l\\'MSM ha ampiamente riferito di quanto fosse imbarazzante.\\n\\n Ora che sappiamo che Zelensky era impegnato a nascondere il coinvolgimento dello Stato ucraino nei biolabs Deep State, (vedi decreto per bruciare i documenti di Metabiota State), possiamo capire PERCHÉ sembrava pietrificato.\\n\\n Trump stava inviando un messaggio a Zelensky.  Trump stava MINACCENDO Zelensky, quando ha detto che lui e Putin \"dovrebbero stare insieme\".\\n\\n Lui sapeva.\\n\\n -Clandestino\\n\\n', 'text_b': None, 'label': 1}, {'guid': 361, 'text_a': '**CLAMOROSO!\\n**Mentre noi parliamo di green pass, la Norvegia torna alla normalità\\n\\n🇮🇹 ', 'text_b': None, 'label': 0}, {'guid': 363, 'text_a': 'Vi stupite ? \\nSono 2 anni ormai che fanno qualsiasi cosa , contro ogni legge , articolo della costituzione e convenzioni internazionali', 'text_b': None, 'label': 1}, {'guid': 368, 'text_a': 'Ma perché scomodarsi per un problema che NON CI RIGUARDA\\n\\nLa mia multa (o quello che è) è MARCITA in posta per un mese per poi tornargli indietro con un #VAFFA spirituale 😎\\n\\n', 'text_b': None, 'label': 0}]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "result, model_outputs, wrong_predictions = model.eval_model(eval_df)\n",
    "print(result)\n",
    "print(wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:simpletransformers.classification.classification_utils: Converting to features started. Cache is not used.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085ab2396b994879a7d2f63e1299800b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_pred = model.predict(eval_df.text.tolist())\n",
    "pred = full_pred[0]\n",
    "raw_pred = full_pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that prints the classification report\n",
    "def report_scores(test_label, test_pred):\n",
    "    print(classification_report(test_label, \n",
    "                            test_pred, \n",
    "                            target_names=['non-conspiratorial', 'conspiratorial']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    precision    recall  f1-score   support\n",
      "\n",
      "non-conspiratorial       0.79      0.84      0.81       184\n",
      "    conspiratorial       0.83      0.77      0.80       185\n",
      "\n",
      "          accuracy                           0.81       369\n",
      "         macro avg       0.81      0.81      0.81       369\n",
      "      weighted avg       0.81      0.81      0.81       369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_scores(eval_df.labels.tolist(), pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b84e03406fad7331f9182d0161376e9e99307f2e683e4e4e928142269a591da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
